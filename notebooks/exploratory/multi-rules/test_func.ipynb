{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe958781",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f6b248ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import importlib\n",
    "\n",
    "# Set up the Python path for the project.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import evals_utils\n",
    "importlib.reload(evals_utils)\n",
    "\n",
    "from inference_utils import build_classification_prompt, build_articulation_prompt, chat, make_inference_fn\n",
    "from evals_utils import load_expected_labels, evaluate_classification_accuracy, parse_predictions, classify_then_explain, flexible_parse_predictions\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919f13f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key loaded.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # reads from .env in current working directory\n",
    "# You can also specify path manually: load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# Confirm it worked:\n",
    "assert \"OPENAI_API_KEY\" in os.environ\n",
    "print(\"OpenAI key loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f07e03",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92003f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPT-4 Models:\n",
      "- gpt-4o-audio-preview-2024-12-17\n",
      "- gpt-4o-audio-preview-2024-10-01\n",
      "- gpt-4-turbo-preview\n",
      "- gpt-4-turbo\n",
      "- gpt-4-turbo-2024-04-09\n",
      "- gpt-4.1-nano\n",
      "- gpt-4.1-nano-2025-04-14\n",
      "- gpt-4o-realtime-preview-2024-10-01\n",
      "- gpt-4o-realtime-preview\n",
      "- gpt-4\n",
      "- chatgpt-4o-latest\n",
      "- gpt-4o-realtime-preview-2024-12-17\n",
      "- gpt-4o-mini-audio-preview\n",
      "- gpt-4o-audio-preview\n",
      "- gpt-4o-mini-realtime-preview\n",
      "- gpt-4.1-mini\n",
      "- gpt-4o-mini-realtime-preview-2024-12-17\n",
      "- gpt-4o-mini-search-preview\n",
      "- gpt-4.1-mini-2025-04-14\n",
      "- gpt-4o-search-preview\n",
      "- gpt-4-1106-preview\n",
      "- gpt-4o-mini-search-preview-2025-03-11\n",
      "- gpt-4-0125-preview\n",
      "- gpt-4o-2024-11-20\n",
      "- gpt-4o-2024-05-13\n",
      "- gpt-4-0613\n",
      "- gpt-4o-mini-tts\n",
      "- gpt-4o-transcribe\n",
      "- gpt-4.5-preview\n",
      "- gpt-4.5-preview-2025-02-27\n",
      "- gpt-4o-mini-transcribe\n",
      "- gpt-4o-search-preview-2025-03-11\n",
      "- gpt-4o\n",
      "- gpt-4o-mini\n",
      "- gpt-4o-2024-08-06\n",
      "- gpt-4.1\n",
      "- gpt-4.1-2025-04-14\n",
      "- gpt-4o-mini-2024-07-18\n",
      "- gpt-4o-mini-audio-preview-2024-12-17\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# Retrieve all available models\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "models = client.models.list()\n",
    "\n",
    "# Filter models that include 'gpt-4' in their ID\n",
    "gpt_4_models = [model.id for model in models.data if \"gpt-4\" in model.id.lower()]\n",
    "\n",
    "# Print the list of GPT-4 models\n",
    "print(\"Available GPT-4 Models:\")\n",
    "for model_id in gpt_4_models:\n",
    "    print(f\"- {model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe2fecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_4o = \"openai/gpt-4o\"\n",
    "model_4o = \"gpt-4o\"\n",
    "openai_4op1 = \"openai/gpt-4.1\"\n",
    "openai_4op1_nano = \"openai/gpt-4.1-nano\"\n",
    "openai_4op1_mini = \"openai/gpt-4.1-mini\"\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43267388",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c398bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def openai_get_response(prompt, model=\"gpt-4\", temperature=0.7, max_tokens=300):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c21cde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "\n",
    "def render_prompt(template_str: str, **kwargs) -> str:\n",
    "    \"\"\"\n",
    "    Render a prompt template.\n",
    "    \n",
    "    - template_str should use `$varname` placeholders (Template syntax),\n",
    "      or you can swap in `.format`-style `{varname}` if you prefer.\n",
    "    - kwargs are the values you want substituted in.\n",
    "    \"\"\"\n",
    "    return Template(template_str).substitute(**kwargs)\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def save_prompt_response(prompt, response, filename, subfolder=\"logs\"):\n",
    "    \"\"\"\n",
    "    Save the prompt and response to a text file in the specified subfolder.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt sent to the LLM\n",
    "        response (str): The response from the LLM\n",
    "        filename (str): Name for the output file (without extension)\n",
    "        subfolder (str): Subfolder to save the file in (default: \"logs\")\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved file\n",
    "    \"\"\"\n",
    "    # Create logs folder if it doesn't exist\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        print(f\"Created folder: {subfolder}\")\n",
    "    \n",
    "    # Add timestamp to filename\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    full_filename = f\"{filename}_{timestamp}.txt\"\n",
    "    file_path = os.path.join(subfolder, full_filename)\n",
    "    \n",
    "    # Write prompt and response to file with clear separation\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"PROMPT:\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(prompt)\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"RESPONSE:\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(response)\n",
    "    \n",
    "    print(f\"Saved prompt and response to {file_path}\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b3ef290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def create_dataset_json(sentences_dict, num_train, num_test, filename, subfolder=\"datasets\"):\n",
    "    \"\"\"\n",
    "    Create and save a JSON dataset with train/test split from a dictionary of TRUE/FALSE sentences.\n",
    "    \n",
    "    Args:\n",
    "        sentences_dict (dict): Dictionary with 'TRUE' and 'FALSE' keys containing lists of sentences\n",
    "        num_train (int): Number of samples for training set\n",
    "        num_test (int): Number of samples for test set\n",
    "        filename (str): Name for the output file (without extension)\n",
    "        subfolder (str): Subfolder to save the file in (default: \"datasets\")\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved file\n",
    "    \"\"\"\n",
    "    # Create datasets folder if it doesn't exist\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        print(f\"Created folder: {subfolder}\")\n",
    "    \n",
    "    # Prepare all samples with labels\n",
    "    all_samples = []\n",
    "    for sentence in sentences_dict['TRUE']:\n",
    "        all_samples.append({\"input\": sentence, \"label\": True})\n",
    "    for sentence in sentences_dict['FALSE']:\n",
    "        all_samples.append({\"input\": sentence, \"label\": False})\n",
    "    \n",
    "    # Shuffle samples\n",
    "    random.shuffle(all_samples)\n",
    "    \n",
    "    # Check if we have enough samples\n",
    "    total_samples = len(all_samples)\n",
    "    if total_samples < (num_train + num_test):\n",
    "        print(f\"Warning: Requested {num_train + num_test} samples but only {total_samples} available.\")\n",
    "        num_train = min(num_train, total_samples // 2)\n",
    "        num_test = min(num_test, total_samples - num_train)\n",
    "        print(f\"Adjusted to {num_train} train and {num_test} test samples.\")\n",
    "    \n",
    "    # Split into train and test\n",
    "    train_samples = all_samples[:num_train]\n",
    "    test_samples = all_samples[num_train:num_train+num_test]\n",
    "    \n",
    "    # Create dataset structure\n",
    "    dataset = {\n",
    "        \"train\": train_samples,\n",
    "        \"test\": test_samples\n",
    "    }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    file_path = os.path.join(subfolder, f\"{filename}.json\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset, f, indent=2)\n",
    "    \n",
    "    print(f\"Dataset saved to {file_path}\")\n",
    "    print(f\"Train samples: {len(train_samples)}, Test samples: {len(test_samples)}\")\n",
    "    \n",
    "    # Print label distribution\n",
    "    train_true = sum(1 for sample in train_samples if sample[\"label\"])\n",
    "    test_true = sum(1 for sample in test_samples if sample[\"label\"])\n",
    "    print(f\"Train labels: {train_true} True, {num_train - train_true} False\")\n",
    "    print(f\"Test labels: {test_true} True, {num_test - test_true} False\")\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a7fd9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sentences(llm_response):\n",
    "    \"\"\"\n",
    "    Extract sentences from LLM response into a dictionary with TRUE and FALSE keys,\n",
    "    filtering out explanations.\n",
    "    \n",
    "    Args:\n",
    "        llm_response (str): The response from the LLM\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with 'TRUE' and 'FALSE' keys containing lists of sentences\n",
    "    \"\"\"\n",
    "    # Initialize result dictionary\n",
    "    result = {\n",
    "        'TRUE': [],\n",
    "        'FALSE': []\n",
    "    }\n",
    "    \n",
    "    # Find the TRUE section\n",
    "    true_pattern = r'## TRUE\\s+((?:\".*?\"\\s*- explanation:.*?\\n)+)'\n",
    "    true_match = re.search(true_pattern, llm_response, re.DOTALL)\n",
    "    \n",
    "    # Find the FALSE section\n",
    "    false_pattern = r'## FALSE\\s+((?:\".*?\"\\s*- explanation:.*?\\n)+)'\n",
    "    false_match = re.search(false_pattern, llm_response, re.DOTALL)\n",
    "    \n",
    "    # Extract TRUE sentences if found\n",
    "    if true_match:\n",
    "        true_text = true_match.group(1)\n",
    "        # Extract just the quoted sentences, ignore explanations\n",
    "        true_sentences = re.findall(r'\"(.*?)\"', true_text)\n",
    "        result['TRUE'] = true_sentences\n",
    "    \n",
    "    # Extract FALSE sentences if found\n",
    "    if false_match:\n",
    "        false_text = false_match.group(1)\n",
    "        # Extract just the quoted sentences, ignore explanations\n",
    "        false_sentences = re.findall(r'\"(.*?)\"', false_text)\n",
    "        result['FALSE'] = false_sentences\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_sentences2(llm_response):\n",
    "    \"\"\"\n",
    "    Extract sentences from LLM response into a dictionary with TRUE and FALSE keys,\n",
    "    filtering out explanations.\n",
    "    \n",
    "    Args:\n",
    "        llm_response (str): The response from the LLM\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with 'TRUE' and 'FALSE' keys containing lists of sentences\n",
    "    \"\"\"\n",
    "    # Initialize result dictionary\n",
    "    result = {\n",
    "        'TRUE': [],\n",
    "        'FALSE': []\n",
    "    }\n",
    "    \n",
    "    # Split the response by sections\n",
    "    true_section = \"\"\n",
    "    false_section = \"\"\n",
    "    \n",
    "    if \"## TRUE\" in llm_response:\n",
    "        sections = llm_response.split(\"## TRUE\", 1)\n",
    "        if len(sections) > 1:\n",
    "            remaining = sections[1]\n",
    "            if \"## FALSE\" in remaining:\n",
    "                parts = remaining.split(\"## FALSE\", 1)\n",
    "                true_section = parts[0].strip()\n",
    "                false_section = parts[1].strip()\n",
    "            else:\n",
    "                true_section = remaining.strip()\n",
    "    \n",
    "    # Process TRUE section\n",
    "    if true_section:\n",
    "        # Look for sentences in quotes at the beginning of each line\n",
    "        lines = true_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line and line.startswith('\"'):\n",
    "                # Extract just the sentence part (before \" - explanation:\")\n",
    "                sentence_match = re.match(r'\"([^\"]+)\".*', line)\n",
    "                if sentence_match:\n",
    "                    result['TRUE'].append(sentence_match.group(1))\n",
    "    \n",
    "    # Process FALSE section\n",
    "    if false_section:\n",
    "        # Look for sentences in quotes at the beginning of each line\n",
    "        lines = false_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line and line.startswith('\"'):\n",
    "                # Extract just the sentence part (before \" - explanation:\")\n",
    "                sentence_match = re.match(r'\"([^\"]+)\".*', line)\n",
    "                if sentence_match:\n",
    "                    result['FALSE'].append(sentence_match.group(1))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def extract_sentences3(llm_response):\n",
    "    \"\"\"\n",
    "    Extract sentences from LLM response into a dictionary with TRUE and FALSE keys,\n",
    "    filtering out explanations and removing numbering.\n",
    "    \n",
    "    Args:\n",
    "        llm_response (str): The response from the LLM\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with 'TRUE' and 'FALSE' keys containing lists of sentences\n",
    "    \"\"\"\n",
    "    # Initialize result dictionary\n",
    "    result = {\n",
    "        'TRUE': [],\n",
    "        'FALSE': []\n",
    "    }\n",
    "    \n",
    "    # Split the response by sections\n",
    "    true_section = \"\"\n",
    "    false_section = \"\"\n",
    "    \n",
    "    if \"## TRUE\" in llm_response or \"## VERO\" in llm_response:\n",
    "        # Handle both English and Italian headers\n",
    "        if \"## TRUE\" in llm_response:\n",
    "            sections = llm_response.split(\"## TRUE\", 1)\n",
    "        else:\n",
    "            sections = llm_response.split(\"## VERO\", 1)\n",
    "            \n",
    "        if len(sections) > 1:\n",
    "            remaining = sections[1]\n",
    "            if \"## FALSE\" in remaining:\n",
    "                parts = remaining.split(\"## FALSE\", 1)\n",
    "                true_section = parts[0].strip()\n",
    "                false_section = parts[1].strip()\n",
    "            elif \"## FALSO\" in remaining:\n",
    "                parts = remaining.split(\"## FALSO\", 1)\n",
    "                true_section = parts[0].strip()\n",
    "                false_section = parts[1].strip()\n",
    "            else:\n",
    "                true_section = remaining.strip()\n",
    "    \n",
    "    # Process TRUE section\n",
    "    if true_section:\n",
    "        lines = true_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Remove numbering like \"1. \", \"2. \", etc.\n",
    "            line = re.sub(r'^\\d+\\.\\s*', '', line)\n",
    "            \n",
    "            # Extract the sentence part (in quotes)\n",
    "            sentence_match = re.search(r'\"([^\"]+)\"', line)\n",
    "            if sentence_match:\n",
    "                result['TRUE'].append(sentence_match.group(1))\n",
    "    \n",
    "    # Process FALSE section\n",
    "    if false_section:\n",
    "        lines = false_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Remove numbering like \"1. \", \"2. \", etc.\n",
    "            line = re.sub(r'^\\d+\\.\\s*', '', line)\n",
    "            \n",
    "            # Extract the sentence part (in quotes)\n",
    "            sentence_match = re.search(r'\"([^\"]+)\"', line)\n",
    "            if sentence_match:\n",
    "                result['FALSE'].append(sentence_match.group(1))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465bc41",
   "metadata": {},
   "source": [
    "### Rule 2: Alliteration Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated template with structured output format including explanations\n",
    "sentence_template = \"\"\" Generate $total sentences following this template: \"[Subject] [verb] [object] while [subject2] [verb2] [object2].\"\n",
    "\n",
    "For $true_count sentences: Include AT LEAST $min_same content words (nouns, verbs, adjectives, adverbs) that begin with the same letter  \n",
    "For $false_count sentences: Ensure NO MORE THAN $max_same content words begin with the same letter\n",
    "\n",
    "Content words are nouns, verbs, adjectives, adverbs. Articles, prepositions, and conjunctions don't count.\n",
    "\n",
    "IMPORTANT: For TRUE sentences, vary your approach. Some sentences should have subjects with DIFFERENT starting letters, where the alliteration comes from other content words. Avoid creating a pattern where most TRUE sentences have matching names.\n",
    "\n",
    "Format your response exactly as follows:\n",
    "\n",
    "## TRUE\n",
    "\"Sentence 1.\" - explanation: (brief explanation)\n",
    "\"Sentence 2.\" - explanation: (brief explanation)\n",
    "\"Sentence 3.\" - explanation: (brief explanation)\n",
    "...\n",
    "\n",
    "## FALSE\n",
    "\"Sentence 1.\" - explanation: (brief explanation)\n",
    "\"Sentence 2.\" - explanation: (brief explanation)\n",
    "\"Sentence 3.\" - explanation: (brief explanation)\n",
    "...\n",
    "\n",
    "Examples:\n",
    "- \"Peter picked peppers while Wendy watched wolves.\" - explanation: (p,p,p - alliteration with first name and two verbs)\n",
    "- \"Sarah silently sorted samples while Tom tested tubes.\" - explanation: (s,s,s,t,t - alliteration with first name, adverb, verb and second subject with different object)\n",
    "- \"Mary made music while John jumped joyfully.\" - explanation: (only two j-words, not enough for TRUE)\n",
    "\n",
    "Make sentences natural and sensible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2fd2f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate 100 sentences following this template: \"[Subject] [verb] [object] while [subject2] [verb2] [object2].\"\n",
      "\n",
      "For 50 sentences: Include AT LEAST 3 content words (nouns, verbs, adjectives, adverbs) that begin with the same letter  \n",
      "For 50 sentences: Ensure NO MORE THAN 2 content words begin with the same letter\n",
      "\n",
      "Content words are nouns, verbs, adjectives, adverbs. Articles, prepositions, and conjunctions don't count.\n",
      "\n",
      "IMPORTANT: For TRUE sentences, vary your approach. Some sentences should have subjects with DIFFERENT starting letters, where the alliteration comes from other content words. Avoid creating a pattern where most TRUE sentences have matching names.\n",
      "\n",
      "Format your response exactly as follows:\n",
      "\n",
      "## TRUE\n",
      "\"Sentence 1.\" - explanation: (brief explanation)\n",
      "\"Sentence 2.\" - explanation: (brief explanation)\n",
      "\"Sentence 3.\" - explanation: (brief explanation)\n",
      "...\n",
      "\n",
      "## FALSE\n",
      "\"Sentence 1.\" - explanation: (brief explanation)\n",
      "\"Sentence 2.\" - explanation: (brief explanation)\n",
      "\"Sentence 3.\" - explanation: (brief explanation)\n",
      "...\n",
      "\n",
      "Examples:\n",
      "- \"Peter picked peppers while Wendy watched wolves.\" - explanation: (p,p,p - alliteration with first name and two verbs)\n",
      "- \"Sarah silently sorted samples while Tom tested tubes.\" - explanation: (s,s,s,t,t - alliteration with first name, adverb, verb and second subject with different object)\n",
      "- \"Mary made music while John jumped joyfully.\" - explanation: (only two j-words, not enough for TRUE)\n",
      "\n",
      "Make sentences natural and sensible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    sentence_template,\n",
    "    total=100,           # 8 sentences\n",
    "    true_count=50,      # 3 “True”\n",
    "    false_count=50,     # 5 “False”\n",
    "    min_same=3,        # at least 3 same‑letter content words\n",
    "    max_same=2,        # no more than 2 same‑letter content words\n",
    ")\n",
    "print(data_generation_prompt)\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98e1c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 TRUE sentences and 49 FALSE sentences\n",
      "Saved prompt and response to logs/alliteration_rule_dataset_20250505_084720.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logs/alliteration_rule_dataset_20250505_084720.txt'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")\n",
    "save_prompt_response(data_generation_prompt, response, \"alliteration_rule_dataset\", subfolder=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "723cc792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to datasets/alliteration_rule_dataset_50_50.json\n",
      "Train samples: 50, Test samples: 50\n",
      "Train labels: 30 True, 20 False\n",
      "Test labels: 22 True, 28 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datasets/alliteration_rule_dataset_50_50.json'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset_json(sentences_dict, 50, 50, \"alliteration_rule_dataset_50_50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3910dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = \"You are an expert text classifier that assigns labels based on specific rules. You will be provided with training examples that demonstrate the classification rule, followed by test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = \"Remember to output only True or False for each test example, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/alliteration_rule_dataset_50_50.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2d5dd993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.76), np.float64(0.74), np.float64(0.74), np.float64(0.82)], 'mean_accuracy': 0.765, 'std_accuracy': 0.03278719262150998, 'overall_accuracy': 0.765, 'all_outs': ['True\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse', 'True\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse', 'True\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/alliteration_rule_dataset_50_50.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1_mini, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f16bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/gpt-4.1) —\n",
      "**Rule:**  \n",
      "Both people mentioned in the sentence must perform actions in which the key nouns (objects or subjects) in their respective clauses all start with the same letter as their own first name.\n",
      "\n",
      "---\n",
      "\n",
      "**Elaboration:**  \n",
      "- Each sentence has two people, each doing an activity (e.g., \"Nadia needed new needles\" and \"Carrie counted colorful cards\").\n",
      "- For a sentence to be labeled True:\n",
      "  - For both people, the nouns or main objects associated with their verbs start with the same letter as their first name.\n",
      "    - Example: \"Nadia needed new needles\" — Nadia, needed, new, needles (all N's).\n",
      "    - \"Carrie counted colorful cards\" — Carrie, counted, colorful, cards (all C's).\n",
      "- If either person's key nouns/objects do **not** start with the same letter as their name, the sentence is labeled False.\n",
      "    - Example: \"Anna checked her messages\" — Anna (A), checked (C), messages (M): mismatch, so False.\n",
      "    - \"Carmen sang a tune\" — Carmen (C), sang (S), tune (T): mismatch, so False.\n",
      "\n",
      "**Short version:**  \n",
      "**Both people's actions must include nouns/objects (and often adjectives) that alliterate with their own first names for the label to be True.**\n",
      "\n",
      "— Choice 2 (openai/gpt-4.1) —\n",
      "**Rule:**  \n",
      "Both people in the sentence are performing actions where each person's action contains a sequence of words (usually a noun phrase) in which the majority of the words start with the same letter as that person's name.\n",
      "\n",
      "---\n",
      "\n",
      "**Elaboration:**  \n",
      "- In the True examples, each person mentioned (before and after \"while\") is performing an activity where the action or the object of the action features alliteration with their name. That is, the words in the activity (especially key nouns and adjectives) start with the same letter as the person's first name.\n",
      "    - For example, \"Nadia needed new needles\" (Nadia – needed, new, needles: all start with N); \"Carrie counted colorful cards\" (Carrie – counted, colorful, cards: all C).\n",
      "    - This applies to both people in the sentence.\n",
      "- In the False examples, at least one person's action does **not** contain such alliterative phrasing with their name.\n",
      "    - For example, \"Carmen sang a tune\" (Carmen – sang a tune: no alliteration with C); \"Fred built a shed\" (Fred – built a shed: no alliteration with F).\n",
      "\n",
      "**In summary:**  \n",
      "For a sentence to be labeled True, both individuals' actions must feature phrases where the majority of the words (especially the main verb and nouns/adjectives) start with the same letter as their respective first names. If this is not true for either person, the sentence is labeled False.\n",
      "\n",
      "— Choice 3 (openai/gpt-4.1) —\n",
      "**Rule:**  \n",
      "The sentence is labeled True if, in each clause, the subject's first name and the main nouns or verbs in their clause all start with the same letter; otherwise, it is labeled False.\n",
      "\n",
      "**Elaboration:**  \n",
      "- Each sentence consists of two clauses (joined by \"while\").  \n",
      "- In a True example, for both clauses, the subject's first name and the significant words (usually the main verbs and/or nouns) in their clause start with the same letter as the subject's name.  \n",
      "    - For example, in \"Paula planted pink petunias while Rosa rearranged red roses.\":  \n",
      "        - \"Paula planted pink petunias\": P, P, P, P.  \n",
      "        - \"Rosa rearranged red roses\": R, R, R, R.  \n",
      "- In False examples, this pattern is broken in at least one clause: either the subject's name does not match the main verb/nouns, or the alliteration is not maintained.  \n",
      "    - For example, \"Carmen sang a tune while Fred built a shed.\":  \n",
      "        - \"Carmen sang a tune\": C [subject], S [verb], T [noun] → not all the same letter.\n",
      "\n",
      "**Summary:**  \n",
      "Both clauses must feature alliteration between the subject's first name and the main words in their action for the sentence to be labeled True. If this is not the case for either clause, it is labeled False.\n",
      "\n",
      "— Choice 4 (openai/gpt-4.1) —\n",
      "**Rule:**  \n",
      "An example is labeled True if and only if the activities described for both people in the sentence each contain at least two consecutive words that begin with the same letter as the person's name.\n",
      "\n",
      "**Elaboration:**  \n",
      "- For each person mentioned, their activity must include a sequence of at least two adjacent words (not counting their own name) that all begin with the same letter as that person's first name.\n",
      "- This alliteration must occur for both people in the sentence.\n",
      "- If either person's activity does not have this feature, the label is False.\n",
      "\n",
      "**Examples:**\n",
      "- \"Nadia needed new needles while Carrie counted colorful cards.\"  \n",
      "  - Nadia: \"needed new needles\" (three N words, matches 'N')  \n",
      "  - Carrie: \"counted colorful cards\" (three C words, matches 'C')  \n",
      "  → True\n",
      "\n",
      "- \"Carmen sang a tune while Fred built a shed.\"  \n",
      "  - Carmen: \"sang a tune\" (no two adjacent words starting with 'C')  \n",
      "  - Fred: \"built a shed\" (no two adjacent words starting with 'F')  \n",
      "  → False\n",
      "\n",
      "- \"Tammy trimmed tiny topiaries while Greg guessed green grapes.\"  \n",
      "  - Tammy: \"trimmed tiny topiaries\" (three T words, matches 'T')  \n",
      "  - Greg: \"guessed green grapes\" (three G words, matches 'G')  \n",
      "  → True\n",
      "\n",
      "- \"Jake repaired the fence while Heather read a story.\"  \n",
      "  - Jake: \"repaired the fence\" (no two adjacent words starting with 'J')  \n",
      "  - Heather: \"read a story\" (no two adjacent words starting with 'H')  \n",
      "  → False\n",
      "\n",
      "— Choice 5 (openai/gpt-4.1) —\n",
      "**Rule:**  \n",
      "Each clause in the sentence describes a person performing an action in which the person’s name and at least one of the key words in the action (verb, object, or object modifier) start with the same letter; both clauses must follow this pattern for the label to be True.\n",
      "\n",
      "---\n",
      "\n",
      "**Elaboration:**  \n",
      "- The sentence is made of two clauses, each following the pattern: \"[Name] [verb/phrase] [object/etc.] while [Name] [verb/phrase] [object/etc.]\".\n",
      "- For each clause, the **person's name** and at least one of the main words in their action (verb, object, or a descriptive word about the object) **must start with the same letter**.\n",
      "    - Example: \"Nadia needed new needles\" — 'Nadia', 'needed', 'new', 'needles' all start with 'N'.\n",
      "    - Example: \"Carmen sang a tune\" — 'Carmen' and 'sang' do NOT start with the same letter → does not satisfy the rule.\n",
      "- **Both clauses** must independently satisfy this pattern for the sentence to be labeled True.\n",
      "- If either clause does not have this alliterative match between name and action, the label is False.\n",
      "\n",
      "**Summary:**  \n",
      "Each person's name and at least one main word in their action must start with the same letter; both clauses must satisfy this for the sentence to be labeled True.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence first, then you may elaborate if needed.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/alliteration_rule_dataset_50_50.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc69ad6",
   "metadata": {},
   "source": [
    "### Rule 17: Italian word - while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "38dafd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# italian_word_template = \"\"\" Generate $total sentences following this template: \"[Subject] [verb] [object] while [subject2] [verb2] [object2].\"\n",
    "\n",
    "# For $true_count sentences: Include EXACTLY ONE Italian word naturally integrated into the otherwise English sentence\n",
    "# For $false_count sentences: Use ONLY English words, with no Italian words\n",
    "\n",
    "# IMPORTANT: For TRUE sentences:\n",
    "# - The Italian word should fit naturally in the sentence context\n",
    "# - Vary the part of speech of the Italian word (nouns, verbs, adjectives, adverbs)\n",
    "# - Avoid overusing stereotypical Italian words like \"pizza\", \"pasta\", \"gelato\"\n",
    "# - The Italian word could appear in any position in the sentence\n",
    "# - Ensure the Italian word is actually Italian, not Spanish or Latin\n",
    "\n",
    "# Format your response exactly as follows:\n",
    "\n",
    "# ## TRUE\n",
    "# \"Sentence 1.\" - explanation: (identifies the Italian word and its meaning)\n",
    "# \"Sentence 2.\" - explanation: (identifies the Italian word and its meaning)\n",
    "# \"Sentence 3.\" - explanation: (identifies the Italian word and its meaning)\n",
    "# ...\n",
    "\n",
    "# ## FALSE\n",
    "# \"Sentence 1.\" - explanation: (confirms all words are English)\n",
    "# \"Sentence 2.\" - explanation: (confirms all words are English)\n",
    "# \"Sentence 3.\" - explanation: (confirms all words are English)\n",
    "# ...\n",
    "\n",
    "# Examples:\n",
    "# - \"Mary made music while John jumped allegramente.\" - explanation: (\"allegramente\" is Italian for \"cheerfully\")\n",
    "# - \"The chef prepared the meal with fresh pomodori from the garden.\" - explanation: (\"pomodori\" is Italian for \"tomatoes\")\n",
    "# - \"Thomas walked slowly to the park while birds sang loudly.\" - explanation: (all words are English)\n",
    "\n",
    "# Make sentences natural, varied, and sensible. The Italian words should feel like a natural code-switch, not forced insertions.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e00480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_word_template = \"\"\" Generate $total sentences following this template: \"[Subject] [verb] [object] while [subject2] [verb2] [object2].\"\n",
    "\n",
    "For $true_count sentences: Include EXACTLY ONE Italian word naturally integrated into the otherwise English sentence\n",
    "For $false_count sentences: Use ONLY English words, with no Italian words\n",
    "\n",
    "IMPORTANT FOR TRUE SENTENCES:\n",
    "- Use only common English names for people (like John, Mary, Sarah, David, etc.)\n",
    "- The Italian word should NOT be a name or proper noun\n",
    "- The Italian word must be a common noun, verb, adjective, or adverb\n",
    "- Vary the part of speech of the Italian word across examples\n",
    "- Avoid stereotypical Italian words like \"pizza\", \"pasta\", \"gelato\"\n",
    "- The Italian word should fit naturally in the sentence context\n",
    "\n",
    "Format your response exactly as follows:\n",
    "\n",
    "## TRUE\n",
    "\"Sentence 1.\" - explanation: (identifies the Italian word and its meaning)\n",
    "\"Sentence 2.\" - explanation: (identifies the Italian word and its meaning)\n",
    "\"Sentence 3.\" - explanation: (identifies the Italian word and its meaning)\n",
    "...\n",
    "\n",
    "## FALSE\n",
    "\"Sentence 1.\" - explanation: (confirms all words are English)\n",
    "\"Sentence 2.\" - explanation: (confirms all words are English)\n",
    "\"Sentence 3.\" - explanation: (confirms all words are English)\n",
    "...\n",
    "\n",
    "Examples:\n",
    "- \"Mary made music while John jumped allegramente.\" - explanation: (\"allegramente\" is Italian for \"cheerfully\")\n",
    "- \"The chef prepared the meal with fresh pomodori from the garden.\" - explanation: (\"pomodori\" is Italian for \"tomatoes\")\n",
    "- \"Thomas walked slowly to the park while birds sang loudly.\" - explanation: (all words are English)\n",
    "\n",
    "Make sentences natural, varied, and sensible. The Italian words should feel like a natural code-switch, not forced insertions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "caf05cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generate 60 sentences following this template: \"[Subject] [verb] [object] while [subject2] [verb2] [object2].\"\n",
      "\n",
      "For 30 sentences: Include EXACTLY ONE Italian word naturally integrated into the otherwise English sentence\n",
      "For 30 sentences: Use ONLY English words, with no Italian words\n",
      "\n",
      "IMPORTANT FOR TRUE SENTENCES:\n",
      "- Use only common English names for people (like John, Mary, Sarah, David, etc.)\n",
      "- The Italian word should NOT be a name or proper noun\n",
      "- The Italian word must be a common noun, verb, adjective, or adverb\n",
      "- Vary the part of speech of the Italian word across examples\n",
      "- Avoid stereotypical Italian words like \"pizza\", \"pasta\", \"gelato\"\n",
      "- The Italian word should fit naturally in the sentence context\n",
      "\n",
      "Format your response exactly as follows:\n",
      "\n",
      "## TRUE\n",
      "\"Sentence 1.\" - explanation: (identifies the Italian word and its meaning)\n",
      "\"Sentence 2.\" - explanation: (identifies the Italian word and its meaning)\n",
      "\"Sentence 3.\" - explanation: (identifies the Italian word and its meaning)\n",
      "...\n",
      "\n",
      "## FALSE\n",
      "\"Sentence 1.\" - explanation: (confirms all words are English)\n",
      "\"Sentence 2.\" - explanation: (confirms all words are English)\n",
      "\"Sentence 3.\" - explanation: (confirms all words are English)\n",
      "...\n",
      "\n",
      "Examples:\n",
      "- \"Mary made music while John jumped allegramente.\" - explanation: (\"allegramente\" is Italian for \"cheerfully\")\n",
      "- \"The chef prepared the meal with fresh pomodori from the garden.\" - explanation: (\"pomodori\" is Italian for \"tomatoes\")\n",
      "- \"Thomas walked slowly to the park while birds sang loudly.\" - explanation: (all words are English)\n",
      "\n",
      "Make sentences natural, varied, and sensible. The Italian words should feel like a natural code-switch, not forced insertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    italian_word_template,\n",
    "    total=60,        # 80 sentences total\n",
    "    true_count=30,   # 40 \"True\" sentences\n",
    "    false_count=30   # 40 \"False\" sentences\n",
    ")\n",
    "print(data_generation_prompt)\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a621cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 TRUE sentences and 30 FALSE sentences\n",
      "Saved prompt and response to logs/alliteration_rule_dataset_it_60_v2_20250505_101713.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logs/alliteration_rule_dataset_it_60_v2_20250505_101713.txt'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences2(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")\n",
    "save_prompt_response(data_generation_prompt, response, \"alliteration_rule_dataset_it_60_v2\", subfolder=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "060805e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to datasets/alliteration_rule_dataset_it_60_30_30_v2.json\n",
      "Train samples: 30, Test samples: 30\n",
      "Train labels: 17 True, 13 False\n",
      "Test labels: 14 True, 16 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datasets/alliteration_rule_dataset_it_60_30_30_v2.json'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset_json(sentences_dict, 30, 30, \"alliteration_rule_dataset_it_60_30_30_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d3c62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = \"You are an expert text classifier that assigns labels based on specific rules. You will be provided with training examples that demonstrate the classification rule, followed by test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = \"Remember to output only True or False for each test example, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/alliteration_rule_dataset_it_60_30_30_v2.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0dad198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert text classifier that assigns labels based on specific rules. You will be provided with training examples that demonstrate the classification rule, followed by test examples that you need to classify using the same rule.\n",
      "Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\n",
      "\n",
      "### Training examples\n",
      "\"Chris played the guitar while Amy sang a song.\" -> False\n",
      "\"Peter jotted notes sulla carta while Jane listened closely.\" -> True\n",
      "\"Jessica chose una maglia while Rob sorted the laundry.\" -> True\n",
      "\"Lauren ate her panino while George told a story.\" -> True\n",
      "\"Hannah swept the porch while Ethan watered the flowers.\" -> False\n",
      "\"Jerry admired the quadro while Olivia drew a sketch.\" -> True\n",
      "\"Grace painted her nails while Nick made a call.\" -> False\n",
      "\"Charlie sketched an albero while Julia watched the sunset.\" -> True\n",
      "\"David prepared breakfast while Sarah quickly added zucchero to her coffee.\" -> True\n",
      "\"Nicole drafted a letter sulla scrivania while Adam organized notes.\" -> True\n",
      "\"Ella texted her friend while Sam drank juice.\" -> False\n",
      "\"Ben packed his valigia while Laura checked the map.\" -> True\n",
      "\"Edward shared a dolce with Mary while they chatted.\" -> True\n",
      "\"Jack built a shelf while Holly sorted the books.\" -> False\n",
      "\"Peter called his friend while Rachel made coffee.\" -> False\n",
      "\"Ashley closed the finestra while Kevin made tea.\" -> True\n",
      "\"Chloe ate breakfast while Colin brewed coffee.\" -> False\n",
      "\"Violet checked the weather while Henry made plans for dinner.\" -> False\n",
      "\"Jack scrambled the uova while Nina toasted bread.\" -> True\n",
      "\"Brian washed the car while Megan cleaned the garage.\" -> False\n",
      "\"Chris cleaned the cucina while Amy set the table.\" -> True\n",
      "\"Paul greeted the ragazza while Lucy waited outside.\" -> True\n",
      "\"Greg ate the mela while Helen packed her bag.\" -> True\n",
      "\"Joshua fed the dog while Mia cleaned the cage.\" -> False\n",
      "\"Thomas walked slowly to the park while birds sang loudly.\" -> False\n",
      "\"Lisa drew a picture while Olivia colored it in.\" -> False\n",
      "\"Jason painted the muro while Emma swept the floor.\" -> True\n",
      "\"Patrick wore a giacca while Diana carried an umbrella.\" -> True\n",
      "\"Susan brushed her capelli while Katie sang a song.\" -> True\n",
      "\"Matthew sewed a button while Annie pressed the shirt.\" -> False\n",
      "\n",
      "### Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\n",
      "\"Patrick put on his shoes while Liz waited at the door.\" ->\n",
      "\"Ben answered the phone while Jane looked for her keys.\" ->\n",
      "\"Owen filled the bird feeder while Ava watched from the window.\" ->\n",
      "\"Alice fixed dinner while John set the table.\" ->\n",
      "\"Emma whispered piano while Daniel closed the window.\" ->\n",
      "\"Kevin turned off the light while Sarah locked the door.\" ->\n",
      "\"Sophie checked the recipe while Drew preheated the oven.\" ->\n",
      "\"Liam fixed the lampada while Molly dusted the shelves.\" ->\n",
      "\"Tony relaxed on the divano while Maggie read a book.\" ->\n",
      "\"Rebecca played chess while Tom read a magazine.\" ->\n",
      "\"Jason arranged the chairs while Emma fetched more cups.\" ->\n",
      "\"Tyler made a sandwich while Zoe poured some milk.\" ->\n",
      "\"Rebecca polished the bicchiere while Sam arranged the plates.\" ->\n",
      "\"Carol hurried downstairs mentre Ethan waited in the hall.\" ->\n",
      "\"Keith read the giornale while Betty checked her phone.\" ->\n",
      "\"Emily cleaned the windows while Matt fed the cat.\" ->\n",
      "\"Emily described the scena before Michael opened the door.\" ->\n",
      "\"Lisa admired the vista while Mark took pictures.\" ->\n",
      "\"Susan baked cookies while Liam read the news.\" ->\n",
      "\"Hannah tied her scarpe while Oscar zipped his jacket.\" ->\n",
      "\"Rachel stirred the minestra while Tom chopped vegetables.\" ->\n",
      "\"Dylan arranged the fiori while Grace watered the plants.\" ->\n",
      "\"Paul mowed the lawn while Claire trimmed the bushes.\" ->\n",
      "\"Laura opened a book while Simon drank water.\" ->\n",
      "\"Ashley folded the laundry while Greg vacuumed the rug.\" ->\n",
      "\"Samantha wrote a letter while David watered the plants.\" ->\n",
      "\"Jessica combed her hair while Leo brushed his teeth.\" ->\n",
      "\"John organized his lavoro while Anna finished her homework.\" ->\n",
      "\"Brian cooked risotto while Claire poured some juice.\" ->\n",
      "\"Alice moved dolcemente while Steve played the piano.\" ->\n"
     ]
    }
   ],
   "source": [
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: expected 30 preds, got 29\n",
      "Iteration 3\n",
      "Output: False  \n",
      "False  \n",
      "False  \n",
      "True  \n",
      "True  \n",
      "False  \n",
      "False  \n",
      "True  \n",
      "False  \n",
      "False  \n",
      "True  \n",
      "False  \n",
      "True  \n",
      "True  \n",
      "True  \n",
      "False  \n",
      "True  \n",
      "True  \n",
      "False  \n",
      "True  \n",
      "True  \n",
      "True  \n",
      "False  \n",
      "False  \n",
      "False  \n",
      "False  \n",
      "True  \n",
      "True  \n",
      "True  \n",
      "Preds: ['FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE']\n",
      "Expected: ['FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 30 preds, got 29",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[154]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m inference_fn = make_inference_fn(model_name=openai_4o, temperature=\u001b[32m0.7\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Evaluate accuracy (gold_labels loaded elsewhere)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mevaluate_classification_accuracy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassification_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43minference_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpected_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgold_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTRUE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFALSE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/OE-test/code/evals_utils.py:104\u001b[39m, in \u001b[36mevaluate_classification_accuracy\u001b[39m\u001b[34m(prompt, inference_fn, expected_labels, label_set, num_runs)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPreds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m preds, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(preds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    105\u001b[39m acc = np.mean([p == g \u001b[38;5;28;01mfor\u001b[39;00m p, g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds, expected_labels)])\n\u001b[32m    106\u001b[39m run_accuracies.append(acc)\n",
      "\u001b[31mValueError\u001b[39m: Expected 30 preds, got 29"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/alliteration_rule_dataset_it_60_30_30_v2.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dde9e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # natural language articulation\n",
    "# intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "# question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "# instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence first, then you may elaborate if needed.\"\n",
    "# articulation_prompt = build_articulation_prompt(\n",
    "#     \"datasets/alliteration_rule_dataset_it_100_50_50.json\",\n",
    "#     intro=intro,\n",
    "#     instructions=instructions,\n",
    "#     question=question,\n",
    "# )\n",
    "# reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "24b52dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # natural language articulation\n",
    "# intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "# question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "# instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence first. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "# articulation_prompt = build_articulation_prompt(\n",
    "#     \"datasets/alliteration_rule_dataset_it_100_50_50.json\",\n",
    "#     intro=intro,\n",
    "#     instructions=instructions,\n",
    "#     question=question,\n",
    "# )\n",
    "# reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072d126",
   "metadata": {},
   "source": [
    "### Rule 17 - Italian words - simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "65cda02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_word_template = \"\"\"Generate $total sentences following this template: \"[Subject] [verb] [object] [prepositional phrase].\"\n",
    "\n",
    "For $true_count sentences: Include EXACTLY ONE Italian word naturally integrated into the otherwise English sentence\n",
    "For $false_count sentences: Use ONLY English words, with no Italian words\n",
    "\n",
    "IMPORTANT FOR TRUE SENTENCES:\n",
    "- Use only common English names for people (like John, Mary, Sarah, David, etc.)\n",
    "- The Italian word should NOT be a name or proper noun\n",
    "- The Italian word must be a common noun, verb, adjective, or adverb\n",
    "- Vary the part of speech AND POSITION of the Italian word across examples\n",
    "- Place Italian words in different positions - beginning, middle, or end of the sentence\n",
    "- Avoid stereotypical Italian words like \"pizza\", \"pasta\", \"gelato\"\n",
    "- The Italian word should fit naturally in the sentence context\n",
    "\n",
    "Format your response exactly as follows:\n",
    "\n",
    "## TRUE\n",
    "\"Sentence 1.\" - explanation: (identifies the Italian word and its meaning)\n",
    "\"Sentence 2.\" - explanation: (identifies the Italian word and its meaning)\n",
    "\"Sentence 3.\" - explanation: (identifies the Italian word and its meaning)\n",
    "...\n",
    "\n",
    "## FALSE\n",
    "\"Sentence 1.\" - explanation: (confirms all words are English)\n",
    "\"Sentence 2.\" - explanation: (confirms all words are English)\n",
    "\"Sentence 3.\" - explanation: (confirms all words are English)\n",
    "...\n",
    "\n",
    "Examples:\n",
    "- \"Sarah enjoyed her piccolo sandwich during the picnic.\" - explanation: (\"piccolo\" is Italian for \"small\")\n",
    "- \"The bambini played happily in the backyard.\" - explanation: (\"bambini\" is Italian for \"children\")\n",
    "- \"John bought fresh vegetables from the local market.\" - explanation: (all words are English)\n",
    "\n",
    "Make sentences natural, varied, and sensible. The Italian words should feel like a natural code-switch, not forced insertions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2e20f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 60 sentences following this template: \"[Subject] [verb] [object] [prepositional phrase].\"\n",
      "\n",
      "For 30 sentences: Include EXACTLY ONE Italian word naturally integrated into the otherwise English sentence\n",
      "For 30 sentences: Use ONLY English words, with no Italian words\n",
      "\n",
      "IMPORTANT FOR TRUE SENTENCES:\n",
      "- Use only common English names for people (like John, Mary, Sarah, David, etc.)\n",
      "- The Italian word should NOT be a name or proper noun\n",
      "- The Italian word must be a common noun, verb, adjective, or adverb\n",
      "- Vary the part of speech AND POSITION of the Italian word across examples\n",
      "- Place Italian words in different positions - beginning, middle, or end of the sentence\n",
      "- Avoid stereotypical Italian words like \"pizza\", \"pasta\", \"gelato\"\n",
      "- The Italian word should fit naturally in the sentence context\n",
      "\n",
      "Format your response exactly as follows:\n",
      "\n",
      "## TRUE\n",
      "\"Sentence 1.\" - explanation: (identifies the Italian word and its meaning)\n",
      "\"Sentence 2.\" - explanation: (identifies the Italian word and its meaning)\n",
      "\"Sentence 3.\" - explanation: (identifies the Italian word and its meaning)\n",
      "...\n",
      "\n",
      "## FALSE\n",
      "\"Sentence 1.\" - explanation: (confirms all words are English)\n",
      "\"Sentence 2.\" - explanation: (confirms all words are English)\n",
      "\"Sentence 3.\" - explanation: (confirms all words are English)\n",
      "...\n",
      "\n",
      "Examples:\n",
      "- \"Sarah enjoyed her piccolo sandwich during the picnic.\" - explanation: (\"piccolo\" is Italian for \"small\")\n",
      "- \"The bambini played happily in the backyard.\" - explanation: (\"bambini\" is Italian for \"children\")\n",
      "- \"John bought fresh vegetables from the local market.\" - explanation: (all words are English)\n",
      "\n",
      "Make sentences natural, varied, and sensible. The Italian words should feel like a natural code-switch, not forced insertions.\n"
     ]
    }
   ],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    italian_word_template,\n",
    "    total=60,        # 80 sentences total\n",
    "    true_count=30,   # 40 \"True\" sentences\n",
    "    false_count=30   # 40 \"False\" sentences\n",
    ")\n",
    "print(data_generation_prompt)\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "61d8c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 TRUE sentences and 30 FALSE sentences\n",
      "Saved prompt and response to logs/alliteration_rule_dataset_it_60_simpl_20250505_102735.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logs/alliteration_rule_dataset_it_60_simpl_20250505_102735.txt'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences2(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")\n",
    "save_prompt_response(data_generation_prompt, response, \"alliteration_rule_dataset_it_60_simpl\", subfolder=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "be183dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to datasets/alliteration_rule_dataset_it_60_30_30_simpl.json\n",
      "Train samples: 30, Test samples: 30\n",
      "Train labels: 16 True, 14 False\n",
      "Test labels: 14 True, 16 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datasets/alliteration_rule_dataset_it_60_30_30_simpl.json'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset_json(sentences_dict, 30, 30, \"alliteration_rule_dataset_it_60_30_30_simpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5d89c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = \"You are an expert text classifier that assigns labels based on specific rules. You will be provided with training examples that demonstrate the classification rule, followed by test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = \"Remember to output only True or False for each test example, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/alliteration_rule_dataset_it_60_30_30_simpl.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f988979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], 'mean_accuracy': 1.0, 'std_accuracy': 0.0, 'overall_accuracy': 1.0, 'all_outs': ['False\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue', 'False\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue', 'False\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue', 'False\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/alliteration_rule_dataset_it_60_30_30_simpl.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b910bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/gpt-4.1) —\n",
      "A sentence is labeled True if it contains at least one Italian word or phrase; otherwise, it is labeled False.\n",
      "\n",
      "— Choice 2 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if it contains at least one Italian word; otherwise, it is labeled False.\n",
      "\n",
      "— Choice 3 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if it contains at least one Italian word; otherwise, it is labeled False.\n",
      "\n",
      "— Choice 4 (openai/gpt-4.1) —\n",
      "A sentence is labeled True if it contains at least one Italian word; otherwise, it is labeled False.\n",
      "\n",
      "— Choice 5 (openai/gpt-4.1) —\n",
      "A sentence is labeled True if it contains at least one Italian word; otherwise, it is labeled False.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/alliteration_rule_dataset_it_60_30_30_simpl.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b209c7b",
   "metadata": {},
   "source": [
    "### Rule 16: Outdoors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5667a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdoors_template = \"\"\" Generate $total sentences following this template: \"[Subject] [verb] [object/activity] [preposition] [location] [time phrase].\"\n",
    "\n",
    "For $true_count sentences: The described activity MUST occur OUTDOORS (in nature, outside buildings, or open-air locations)\n",
    "For $false_count sentences: The described activity MUST occur INDOORS (inside buildings or enclosed spaces)\n",
    "\n",
    "IMPORTANT:\n",
    "- Outdoor locations include: parks, forests, beaches, mountains, gardens, playgrounds, streets, fields, lakes, etc.\n",
    "- Indoor locations include: houses, offices, schools, malls, restaurants, theaters, museums, libraries, etc.\n",
    "- Make the setting explicit - either directly state the location or use clear context clues\n",
    "- Vary the activities, locations, and time phrases across examples\n",
    "- Use a mix of individual and group activities\n",
    "- Include different weather conditions and times of day for outdoor activities\n",
    "\n",
    "Format your response exactly as follows:\n",
    "\n",
    "## TRUE\n",
    "\"Sentence 1.\" - explanation: (identifies the outdoor location/setting)\n",
    "\"Sentence 2.\" - explanation: (identifies the outdoor location/setting)\n",
    "\"Sentence 3.\" - explanation: (identifies the outdoor location/setting)\n",
    "...\n",
    "\n",
    "## FALSE\n",
    "\"Sentence 1.\" - explanation: (identifies the indoor location/setting)\n",
    "\"Sentence 2.\" - explanation: (identifies the indoor location/setting)\n",
    "\"Sentence 3.\" - explanation: (identifies the indoor location/setting)\n",
    "...\n",
    "\n",
    "Examples:\n",
    "- \"Children played soccer in the park after school.\" - explanation: (outdoors in a park)\n",
    "- \"The hikers climbed steep trails through the mountains during sunrise.\" - explanation: (outdoors on mountain trails)\n",
    "- \"The family watched movies in their living room last night.\" - explanation: (indoors in a living room)\n",
    "- \"Students studied chemistry in the school laboratory every afternoon.\" - explanation: (indoors in a laboratory)\n",
    "\n",
    "Make sentences natural, varied, and unambiguous about the setting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1d1dbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    outdoors_template,\n",
    "    total=16,        # 80 sentences total\n",
    "    true_count=8,   # 40 \"True\" sentences\n",
    "    false_count=8   # 40 \"False\" sentences\n",
    ")\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d16b3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 TRUE sentences and 8 FALSE sentences\n",
      "Saved prompt and response to logs/outdoors_dataset_it_16_20250505_104815.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logs/outdoors_dataset_it_16_20250505_104815.txt'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences2(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")\n",
    "save_prompt_response(data_generation_prompt, response, \"outdoors_dataset_it_16\", subfolder=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eef05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to datasets/outdoors_dataset_it_16_8_8.json\n",
      "Train samples: 8, Test samples: 8\n",
      "Train labels: 5 True, 3 False\n",
      "Test labels: 3 True, 5 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datasets/outdoors_dataset_it_16_8_8.json'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset_json(sentences_dict, 8, 8, \"outdoors_dataset_it_16_8_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "016ef56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = \"You are an expert text classifier that assigns labels based on specific rules. You will be provided with training examples that demonstrate the classification rule, followed by test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = \"Remember to output only True or False for each test example, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/outdoors_dataset_it_16_8_8.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "22367828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], 'mean_accuracy': 1.0, 'std_accuracy': 0.0, 'overall_accuracy': 1.0, 'all_outs': ['False\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue', 'False\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue', 'False\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue', 'False\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/outdoors_dataset_it_16_8_8.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "70d31c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/gpt-4.1) —\n",
      "The activity takes place outdoors.\n",
      "\n",
      "— Choice 2 (openai/gpt-4.1) —\n",
      "The activity must take place outdoors.\n",
      "\n",
      "— Choice 3 (openai/gpt-4.1) —\n",
      "The activity must take place outdoors (not inside a building or room).\n",
      "\n",
      "— Choice 4 (openai/gpt-4.1) —\n",
      "The activity takes place outdoors (not inside a building or vehicle).\n",
      "\n",
      "— Choice 5 (openai/gpt-4.1) —\n",
      "The activity must take place outdoors, not indoors.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/outdoors_dataset_it_16_8_8.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb506683",
   "metadata": {},
   "source": [
    "### Rule 18: Third Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a26923b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_word_template = \"\"\" Generate $total sentences following this template: \"[Subject] [verb] [third_word] [rest of sentence].\"\n",
    "\n",
    "For $true_count sentences: The THIRD word in the sentence MUST start with a vowel (a, e, i, o, u)\n",
    "For $false_count sentences: The THIRD word in the sentence MUST start with a consonant\n",
    "\n",
    "IMPORTANT:\n",
    "- The third word position is what matters, regardless of its part of speech\n",
    "- Ensure the third word is clearly identifiable (no contractions or hyphenated words before it)\n",
    "- Vary the parts of speech that appear in the third position (nouns, adjectives, verbs, etc.)\n",
    "- Create natural, grammatical sentences with varied vocabulary\n",
    "- Do NOT include any hints or patterns that might reveal the rule (e.g., don't make TRUE sentences shorter or use specific themes)\n",
    "- Names and proper nouns are acceptable in the third position\n",
    "\n",
    "Format your response exactly as follows:\n",
    "\n",
    "## TRUE\n",
    "\"Sentence 1.\" - explanation: (identifies the third word and its starting vowel)\n",
    "\"Sentence 2.\" - explanation: (identifies the third word and its starting vowel)\n",
    "\"Sentence 3.\" - explanation: (identifies the third word and its starting vowel)\n",
    "...\n",
    "\n",
    "## FALSE\n",
    "\"Sentence 1.\" - explanation: (identifies the third word and its starting consonant)\n",
    "\"Sentence 2.\" - explanation: (identifies the third word and its starting consonant)\n",
    "\"Sentence 3.\" - explanation: (identifies the third word and its starting consonant)\n",
    "...\n",
    "\n",
    "Examples:\n",
    "- \"John painted elegant portraits for the local gallery.\" - explanation: (third word \"elegant\" starts with 'e')\n",
    "- \"Children build impressive sandcastles during summer vacation.\" - explanation: (third word \"impressive\" starts with 'i')\n",
    "- \"The teacher reviewed several homework assignments yesterday.\" - explanation: (third word \"several\" starts with 's', a consonant)\n",
    "- \"My dog chased squirrels through the neighborhood park.\" - explanation: (third word \"squirrels\" starts with 's', a consonant)\n",
    "\n",
    "Make sentences varied and natural while strictly following the rule.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8c76efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    third_word_template,\n",
    "    total=40,        # 80 sentences total\n",
    "    true_count=20,   # 40 \"True\" sentences\n",
    "    false_count=20   # 40 \"False\" sentences\n",
    ")\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0369a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 TRUE sentences and 21 FALSE sentences\n",
      "Saved prompt and response to logs/3word_dataset_40_20250505_115626.txt\n",
      "Dataset saved to datasets/3word_dataset_it_100_50_50.json\n",
      "Train samples: 0, Test samples: 40\n",
      "Train labels: 0 True, 0 False\n",
      "Test labels: 19 True, 21 False\n",
      "\n",
      "{'TRUE': ['Maria adopted energetic cats from the shelter.', 'Students invented amazing devices for the science fair.', 'Timothy offered irresistible treats to his puppy.', 'The committee examined unusual proposals carefully yesterday.', 'Cats enjoy outdoor naps during warm afternoons.', 'David earned outstanding grades this semester.', 'She attached elegant ribbons to each bouquet.', 'Roberta organized efficient meetings every Monday.', 'He introduced Olivia at the ceremony.', 'The crew accepted urgent assignments last week.', 'My uncle invested enormous sums in several companies.', 'Jasmine ordered ice-cream after dinner yesterday.', 'Parents offer invaluable support to their children.', 'Michael assisted injured hikers on the mountain trail.', 'Engineers operate advanced equipment safely.', 'Sara explained unusual topics in the class discussion.', 'Drivers encountered unexpected obstacles on the bridge.', 'Linda assigns important work to her team weekly.', 'Tourists explored ancient ruins during their trip.', 'Doctors analyze illnesses using advanced techniques.'], 'FALSE': ['Emily painted bright pictures on large canvases.', 'The dog chased wild rabbits through the field.', 'Jacob built sturdy fences around his property.', 'Children played noisy games in the park.', 'Mark grew delicious tomatoes in his backyard.', 'The pilot spotted distant landmarks during the flight.', 'Students admire brave teachers who inspire them.', 'My sister collects vintage stamps from Europe.', 'Teachers encourage persistent effort from all learners.', 'Liam purchased old books at the market.', 'We watched colorful sunsets over the ocean.', 'The chef prepared fresh salads every day.', 'That musician played joyful melodies last night.', 'Rachel noticed broken branches after the storm.', 'Train engineers maintain powerful engines carefully.', 'Clara baked enormous cookies for the party.', 'Farmers drive large tractors across the fields.', 'Martin explored famous landmarks along the river.', 'The library hosts special events twice monthly.', 'Workers carry heavy materials up the ladder.', 'Lily found several treasures beneath the sand.']}\n"
     ]
    }
   ],
   "source": [
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences2(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")\n",
    "save_prompt_response(data_generation_prompt, response, \"3word_dataset_40\", subfolder=\"logs\")\n",
    "create_dataset_json(sentences_dict, 0, 40, \"3word_dataset_it_100_50_50\")\n",
    "print()\n",
    "print(sentences_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d4208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly 40 training examples that demonstrate the classification rule, followed by exactly 40 test examples that you need to classify using the same rule.\n",
      "Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\n",
      "\n",
      "### Training examples\n",
      "\"Erin avoids unpleasant conflicts whenever possible.\" -> True\n",
      "\"The girl asked careful questions during the tour.\" -> False\n",
      "\"Josh described friendly neighbors to us.\" -> False\n",
      "\"My aunt organized exciting trips every year.\" -> True\n",
      "\"We heard classical music in the park.\" -> False\n",
      "\"Julia borrowed several blankets for camping.\" -> False\n",
      "\"Janet repainted wooden chairs yesterday.\" -> False\n",
      "\"Mason solved tough riddles yesterday.\" -> False\n",
      "\"People discuss important events each morning.\" -> True\n",
      "\"Alex built sturdy bridges over the river.\" -> False\n",
      "\"Patrick broke several pencils last night.\" -> False\n",
      "\"My friend adopted an energetic puppy yesterday.\" -> True\n",
      "\"Harper learned practical skills last year.\" -> False\n",
      "\"Anna understood every instruction right away.\" -> True\n",
      "\"Sophie ordered extra appetizers for the group.\" -> True\n",
      "\"We observed elegant cranes near the lake.\" -> True\n",
      "\"Carla baked fresh muffins on Sunday.\" -> False\n",
      "\"Ava asked Olivia about Saturday's festival.\" -> True\n",
      "\"Clara discovered ancient drums at the fair.\" -> False\n",
      "\"The company unveiled innovative software this year.\" -> True\n",
      "\"He lifts enormous objects at the gym.\" -> True\n",
      "\"The artist examined unusual patterns for reference.\" -> True\n",
      "\"Grandpa enjoys classic novels every fall.\" -> False\n",
      "\"Victor made beautiful pottery every summer.\" -> False\n",
      "\"We admired graceful dancers at the show.\" -> False\n",
      "\"Will collects rare coins from different countries.\" -> False\n",
      "\"Eli discovered hidden caves in Spain.\" -> False\n",
      "\"Hannah delivered spicy curries for dinner.\" -> False\n",
      "\"Luke solved difficult puzzles overnight.\" -> False\n",
      "\"My cousin played soccer after school.\" -> False\n",
      "\"Martin enjoys spicy noodles at dinner.\" -> False\n",
      "\"The chef includes olive oil in every sauce.\" -> True\n",
      "\"Colin wrote an inspiring letter afterward.\" -> True\n",
      "\"Amanda cooked amazing omelets this morning.\" -> True\n",
      "\"They admired unusual paintings during the tour.\" -> True\n",
      "\"Jason expected icy roads after the storm.\" -> True\n",
      "\"Riley saw green parrots near the garden.\" -> False\n",
      "\"Melody studied complex equations before the test.\" -> False\n",
      "\"They designed custom logos for students.\" -> False\n",
      "\"The teacher explained basic grammar rules yesterday.\" -> False\n",
      "\n",
      "### Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\n",
      "\"The chef prepared roasted vegetables tonight.\" ->\n",
      "\"Thomas painted an elaborate mural downtown.\" ->\n",
      "\"Raj offered apples to everyone at lunch.\" ->\n",
      "\"My sister mended torn jeans yesterday.\" ->\n",
      "\"Olivia read about ancient civilizations last night.\" ->\n",
      "\"I found interesting articles online recently.\" ->\n",
      "\"Juliet imagined unusual creatures in her story.\" ->\n",
      "\"We visited elementary schools last month.\" ->\n",
      "\"Lily made excellent arrangements for the play.\" ->\n",
      "\"We climbed rocky hills last weekend.\" ->\n",
      "\"The kids assembled interesting models on the table.\" ->\n",
      "\"My parents started morning walks last autumn.\" ->\n",
      "\"The children brought green apples to share.\" ->\n",
      "\"Ben adopted adorable iguanas from the pet store.\" ->\n",
      "\"Charlie practices guitar on Tuesday evenings.\" ->\n",
      "\"Marcus invited Evelyn to his party.\" ->\n",
      "\"My uncle washed plastic bottles after the barbecue.\" ->\n",
      "\"They explored enormous caves in the valley.\" ->\n",
      "\"Dylan found brown shoes at the store.\" ->\n",
      "\"The dancers rehearsed flawless routines last night.\" ->\n",
      "\"This museum unveiled interesting artifacts recently.\" ->\n",
      "\"Sophia presented detailed information during class.\" ->\n",
      "\"Penny encountered odd situations abroad.\" ->\n",
      "\"My brother offers excellent assistance often.\" ->\n",
      "\"She wore orange earrings during the ceremony.\" ->\n",
      "\"Mia enjoyed unusual recipes for dinner.\" ->\n",
      "\"The gardener uprooted ancient trees last week.\" ->\n",
      "\"The director shared brilliant ideas for improvement.\" ->\n",
      "\"Monica arranged colorful flowers along the windowsill.\" ->\n",
      "\"Tyler watched classic movies over the weekend.\" ->\n",
      "\"Rebecca created beautiful jewelry at home.\" ->\n",
      "\"Rosa observed intricate patterns on the fabric.\" ->\n",
      "\"Lisa borrowed old magazines from the library.\" ->\n",
      "\"Ian enjoyed bold flavors in his meal.\" ->\n",
      "\"Kyle opened an umbrella in the rain.\" ->\n",
      "\"They uncovered old engravings behind the wall.\" ->\n",
      "\"Dan assembled efficient robots at home.\" ->\n",
      "\"The family entered an old cathedral together.\" ->\n",
      "\"Rachel makes delicious cakes every April.\" ->\n",
      "\"James invited unexpected guests to dinner.\" ->\n"
     ]
    }
   ],
   "source": [
    "ntrain = 40\n",
    "ntest = 40\n",
    "intro = f\"You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly {ntrain} training examples that demonstrate the classification rule, followed by exactly {ntest} test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = f\"Remember to output only True or False for each of the {ntest} test examples, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/3word_dataset_it_80_40_40.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "\n",
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fcb1b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.675), np.float64(0.675), np.float64(0.675), np.float64(0.675)], 'mean_accuracy': 0.675, 'std_accuracy': 0.0, 'overall_accuracy': 0.675, 'all_outs': ['True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue', 'True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue', 'True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue', 'True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/3word_dataset_it_80_40_40.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ce6249b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if it contains at least one adjective that begins with a vowel (a, e, i, o, or u).\n",
      "\n",
      "— Choice 2 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if it contains at least one adjective that starts with a vowel (a, e, i, o, or u).\n",
      "\n",
      "— Choice 3 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if and only if the direct object noun immediately following the verb begins with a vowel.\n",
      "\n",
      "— Choice 4 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if it contains at least one adjective that begins with a vowel (a, e, i, o, or u).\n",
      "\n",
      "— Choice 5 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if it contains at least one adjective that begins with a vowel (a, e, i, o, u); otherwise, it is labeled False.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/3word_dataset_it_80_40_40.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbeafb",
   "metadata": {},
   "source": [
    "### La terza parola e' in Italiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "33b341c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "terza_parola_template = \"\"\" Genera $total frasi seguendo questo modello: \"[Soggetto] [verbo] [terza_parola] [resto della frase].\"\n",
    "\n",
    "Per $true_count frasi: La TERZA parola della frase DEVE iniziare con una vocale (a, e, i, o, u)\n",
    "Per $false_count frasi: La TERZA parola della frase DEVE iniziare con una consonante\n",
    "\n",
    "IMPORTANTE:\n",
    "- Ciò che conta è la posizione della terza parola, indipendentemente dalla sua funzione grammaticale\n",
    "- Assicurati che la terza parola sia chiaramente identificabile (niente contrazioni o parole con trattino prima)\n",
    "- Varia le parti del discorso che appaiono in terza posizione (sostantivi, aggettivi, verbi, ecc.)\n",
    "- Crea frasi naturali e grammaticalmente corrette con un vocabolario variato\n",
    "- NON includere indizi o schemi che potrebbero rivelare la regola (ad esempio, non rendere le frasi VERE più corte o usare temi specifici)\n",
    "- I nomi propri sono accettabili in terza posizione\n",
    "\n",
    "Formatta la tua risposta esattamente come segue:\n",
    "\n",
    "## TRUE\n",
    "\"Frase 1.\" - spiegazione: (identifica la terza parola e la sua vocale iniziale)\n",
    "\"Frase 2.\" - spiegazione: (identifica la terza parola e la sua vocale iniziale)\n",
    "\"Frase 3.\" - spiegazione: (identifica la terza parola e la sua vocale iniziale)\n",
    "...\n",
    "\n",
    "## FALSE\n",
    "\"Frase 1.\" - spiegazione: (identifica la terza parola e la sua consonante iniziale)\n",
    "\"Frase 2.\" - spiegazione: (identifica la terza parola e la sua consonante iniziale)\n",
    "\"Frase 3.\" - spiegazione: (identifica la terza parola e la sua consonante iniziale)\n",
    "...\n",
    "\n",
    "Esempi:\n",
    "- \"Marco dipinge eleganti ritratti per la galleria locale.\" - spiegazione: (la terza parola \"eleganti\" inizia con 'e')\n",
    "- \"I bambini costruiscono incredibili castelli di sabbia durante l'estate.\" - spiegazione: (la terza parola \"incredibili\" inizia con 'i')\n",
    "- \"La professoressa corregge diversi compiti di matematica.\" - spiegazione: (la terza parola \"diversi\" inizia con 'd', una consonante)\n",
    "- \"Il mio cane rincorre scoiattoli nel parco del quartiere.\" - spiegazione: (la terza parola \"scoiattoli\" inizia con 's', una consonante)\n",
    "\n",
    "Crea frasi varie e naturali seguendo rigorosamente la regola.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3d81da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    terza_parola_template,\n",
    "    total=80,        # 80 sentences total\n",
    "    true_count=40,   # 40 \"True\" sentences\n",
    "    false_count=40   # 40 \"False\" sentences\n",
    ")\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cc5a8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 TRUE sentences and 40 FALSE sentences\n"
     ]
    }
   ],
   "source": [
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences3(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9a6e4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prompt and response to logs/3word_dataset_80_ita_20250505_125553.txt\n",
      "Dataset saved to datasets/3word_dataset_80_40_40_ita.json\n",
      "Train samples: 40, Test samples: 40\n",
      "Train labels: 19 True, 21 False\n",
      "Test labels: 21 True, 19 False\n",
      "\n",
      "{'TRUE': ['Giulia racconta emozionanti storie davanti al camino.', 'Francesco porta insalata fresca al picnic di domenica.', 'I ragazzi ordinate antipasti prima del pranzo principale.', 'Paolo osserva una aquila sopra la montagna.', 'Le maestre assegnano esercizi difficili agli studenti.', 'Silvia indossa eleganti orecchini durante la festa.', 'Mario ama ascoltare opere liriche la sera.', 'Tu possiedi una automobile molto affidabile.', 'Alessia organizza incontri ogni mese in centro.', 'Sara utilizza internet frequentemente per lavorare.', 'Il direttore annuncia un evento speciale domani.', 'Lorena compra abiti online con sconti.', 'Luca usa energia rinnovabile nella sua casa.', 'Il cane entra impaziente in casa ogni mattina.', 'Mia madre offre una ombra fresca sotto il pino.', 'La nonna ama insegnare inglese ai nipoti.', 'Benedetta protegge un elefante al rifugio.', 'Quel pittore esegue opere astratte magnifiche.', 'Tu impari ogni argomento con impegno.', 'Il piccolo utilizza una agenda digitale.', 'Martina esplora isole greche durante le vacanze.', 'Roberto osserva attentamente ogni attività.', 'I tecnici aggiungono elementi innovativi ai progetti.', 'Mio padre ordina una aranciata ghiacciata d’estate.', 'Ginevra accoglie ospiti entusiasti nella sua casa.', 'Corrado visita un ospedale vicino al centro.', 'Il venditore offre inoltre ottimi consigli pratici.', 'Beatrice acquista arredamento artigianale al mercato.', 'Quei bambini entrano ordinatamente in aula ogni mattina.', 'Mio cugino affitta appartamenti eleganti vicino al mare.', 'L’impiegato invia email urgenti al capo.', 'Tu ottieni incredibili risultati grazie allo studio.', 'I viaggiatori attraversano oceani infiniti sulle navi.', 'Quel negozio offre utili informazioni ai clienti.', 'Le sorelle esaminano ampolle antiche nella soffitta.', 'Il professore accetta una opinione alternativa.', 'Valentina offre esempi efficaci durante la spiegazione.', 'La compagnia utilizza autobus elettrici in città.', 'Il giardiniere annaffia ortensie ogni mattina.', 'Federica esprime un’opinione autorevole durante la riunione.'], 'FALSE': ['Giacomo mangia pane tostato con marmellata.', 'Il bimbo raccoglie conchiglie sulla spiaggia.', 'Livia ordina pizza margherita ogni sabato.', 'Andrea scrive lettere personalizzate agli amici.', 'La donna legge romanzi gialli di notte.', 'Simone compra biscotti integrali alla mattina.', 'I ragazzi puliscono finestre grandi della scuola.', 'Mariella cucina tortellini freschi ogni domenica.', 'Tu ricevi pacchi misteriosi da lontano.', 'Luca trova monete antiche nel giardino.', 'L’infermiere lega fasce sulle braccia.', 'La barista serve cappuccini caldi ogni mattina.', 'I musicisti suonano brani celebri al festival.', 'Lei sistema quadri moderni nel salotto.', 'Le allieve disegnano farfalle colorate nel quaderno.', 'Tuo nonno coltiva piante aromatiche sul balcone.', 'Chiara adora balli tipici dell’America latina.', 'Il cameriere prepara tavoli puliti per la cena.', 'Alessandro compra scarpe nuove ogni mese.', 'Io cucino torte al cioccolato spesso.', 'Martina raccoglie foglie rosse durante l’autunno.', 'Il giovane scrive poesie malinconiche.', 'Lucia invia pacchetti regalo con gioia.', 'Gli atleti vincono medaglie ogni gara.', 'Antonio sceglie magliette comode per la palestra.', 'Noi portiamo valigie pesanti in viaggio.', 'Valeria beve succhi freschi d’arancia.', 'Il gatto graffia divano nuovo ogni notte.', 'Gli insegnanti trovano soluzioni brillanti ai problemi.', 'Mamma pulisce piatti subito dopo cena.', 'Sandra legge libri illustrati ai bambini.', 'I soldati portano zaini pesanti sulle spalle.', 'Tuo fratello indossa maglioni spessi d’inverno.', 'Andrea vende quadri d’autore ogni fiera.', 'La sorella costruisce barchette di carta.', 'Stefano legge quotidiani online la mattina.', 'Io preparo dolci diversi ogni settimana.', 'Federico studia testi antichi al museo.', 'Barbara canta canzoni allegre in macchina.', 'Le ragazze decorano biscotti natalizi insieme.']}\n"
     ]
    }
   ],
   "source": [
    "save_prompt_response(data_generation_prompt, response, \"3word_dataset_80_ita\", subfolder=\"logs\")\n",
    "create_dataset_json(sentences_dict, 40, 40, \"3word_dataset_80_40_40_ita\")\n",
    "print()\n",
    "print(sentences_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b23370e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly 40 training examples that demonstrate the classification rule, followed by exactly 40 test examples that you need to classify using the same rule.\n",
      "Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\n",
      "\n",
      "### Training examples\n",
      "\"Andrea scrive lettere personalizzate agli amici.\" -> False\n",
      "\"Luca trova monete antiche nel giardino.\" -> False\n",
      "\"Le allieve disegnano farfalle colorate nel quaderno.\" -> False\n",
      "\"Mia madre offre una ombra fresca sotto il pino.\" -> True\n",
      "\"La nonna ama insegnare inglese ai nipoti.\" -> True\n",
      "\"I soldati portano zaini pesanti sulle spalle.\" -> False\n",
      "\"Il gatto graffia divano nuovo ogni notte.\" -> False\n",
      "\"Quel negozio offre utili informazioni ai clienti.\" -> True\n",
      "\"Tu impari ogni argomento con impegno.\" -> True\n",
      "\"Federica esprime un’opinione autorevole durante la riunione.\" -> True\n",
      "\"Sandra legge libri illustrati ai bambini.\" -> False\n",
      "\"Corrado visita un ospedale vicino al centro.\" -> True\n",
      "\"Chiara adora balli tipici dell’America latina.\" -> False\n",
      "\"Alessandro compra scarpe nuove ogni mese.\" -> False\n",
      "\"I musicisti suonano brani celebri al festival.\" -> False\n",
      "\"Martina esplora isole greche durante le vacanze.\" -> True\n",
      "\"Il professore accetta una opinione alternativa.\" -> True\n",
      "\"Giulia racconta emozionanti storie davanti al camino.\" -> True\n",
      "\"Paolo osserva una aquila sopra la montagna.\" -> True\n",
      "\"Roberto osserva attentamente ogni attività.\" -> True\n",
      "\"Benedetta protegge un elefante al rifugio.\" -> True\n",
      "\"La compagnia utilizza autobus elettrici in città.\" -> True\n",
      "\"Luca usa energia rinnovabile nella sua casa.\" -> True\n",
      "\"La donna legge romanzi gialli di notte.\" -> False\n",
      "\"I ragazzi ordinate antipasti prima del pranzo principale.\" -> True\n",
      "\"Il bimbo raccoglie conchiglie sulla spiaggia.\" -> False\n",
      "\"Gli insegnanti trovano soluzioni brillanti ai problemi.\" -> False\n",
      "\"Io preparo dolci diversi ogni settimana.\" -> False\n",
      "\"La sorella costruisce barchette di carta.\" -> False\n",
      "\"Gli atleti vincono medaglie ogni gara.\" -> False\n",
      "\"I ragazzi puliscono finestre grandi della scuola.\" -> False\n",
      "\"Mio padre ordina una aranciata ghiacciata d’estate.\" -> True\n",
      "\"Giacomo mangia pane tostato con marmellata.\" -> False\n",
      "\"Martina raccoglie foglie rosse durante l’autunno.\" -> False\n",
      "\"Le sorelle esaminano ampolle antiche nella soffitta.\" -> True\n",
      "\"Federico studia testi antichi al museo.\" -> False\n",
      "\"Valeria beve succhi freschi d’arancia.\" -> False\n",
      "\"Alessia organizza incontri ogni mese in centro.\" -> True\n",
      "\"Quei bambini entrano ordinatamente in aula ogni mattina.\" -> True\n",
      "\"Lei sistema quadri moderni nel salotto.\" -> False\n",
      "\n",
      "### Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\n",
      "\"L’impiegato invia email urgenti al capo.\" ->\n",
      "\"Andrea vende quadri d’autore ogni fiera.\" ->\n",
      "\"Le ragazze decorano biscotti natalizi insieme.\" ->\n",
      "\"Il giovane scrive poesie malinconiche.\" ->\n",
      "\"L’infermiere lega fasce sulle braccia.\" ->\n",
      "\"Tuo nonno coltiva piante aromatiche sul balcone.\" ->\n",
      "\"I viaggiatori attraversano oceani infiniti sulle navi.\" ->\n",
      "\"Noi portiamo valigie pesanti in viaggio.\" ->\n",
      "\"Il cameriere prepara tavoli puliti per la cena.\" ->\n",
      "\"Il cane entra impaziente in casa ogni mattina.\" ->\n",
      "\"La barista serve cappuccini caldi ogni mattina.\" ->\n",
      "\"Tuo fratello indossa maglioni spessi d’inverno.\" ->\n",
      "\"Tu ricevi pacchi misteriosi da lontano.\" ->\n",
      "\"Mamma pulisce piatti subito dopo cena.\" ->\n",
      "\"Quel pittore esegue opere astratte magnifiche.\" ->\n",
      "\"Beatrice acquista arredamento artigianale al mercato.\" ->\n",
      "\"Barbara canta canzoni allegre in macchina.\" ->\n",
      "\"Le maestre assegnano esercizi difficili agli studenti.\" ->\n",
      "\"Stefano legge quotidiani online la mattina.\" ->\n",
      "\"Sara utilizza internet frequentemente per lavorare.\" ->\n",
      "\"Lorena compra abiti online con sconti.\" ->\n",
      "\"Livia ordina pizza margherita ogni sabato.\" ->\n",
      "\"Mario ama ascoltare opere liriche la sera.\" ->\n",
      "\"Mariella cucina tortellini freschi ogni domenica.\" ->\n",
      "\"Valentina offre esempi efficaci durante la spiegazione.\" ->\n",
      "\"Simone compra biscotti integrali alla mattina.\" ->\n",
      "\"Tu ottieni incredibili risultati grazie allo studio.\" ->\n",
      "\"Lucia invia pacchetti regalo con gioia.\" ->\n",
      "\"Mio cugino affitta appartamenti eleganti vicino al mare.\" ->\n",
      "\"Il giardiniere annaffia ortensie ogni mattina.\" ->\n",
      "\"Il venditore offre inoltre ottimi consigli pratici.\" ->\n",
      "\"Tu possiedi una automobile molto affidabile.\" ->\n",
      "\"Francesco porta insalata fresca al picnic di domenica.\" ->\n",
      "\"Ginevra accoglie ospiti entusiasti nella sua casa.\" ->\n",
      "\"Io cucino torte al cioccolato spesso.\" ->\n",
      "\"Antonio sceglie magliette comode per la palestra.\" ->\n",
      "\"Silvia indossa eleganti orecchini durante la festa.\" ->\n",
      "\"I tecnici aggiungono elementi innovativi ai progetti.\" ->\n",
      "\"Il piccolo utilizza una agenda digitale.\" ->\n",
      "\"Il direttore annuncia un evento speciale domani.\" ->\n"
     ]
    }
   ],
   "source": [
    "ntrain = 40\n",
    "ntest = 40\n",
    "intro = f\"You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly {ntrain} training examples that demonstrate the classification rule, followed by exactly {ntest} test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = f\"Remember to output only True or False for each of the {ntest} test examples, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/3word_dataset_80_40_40_ita.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "\n",
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8bade2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.7), np.float64(0.75), np.float64(0.675), np.float64(0.675)], 'mean_accuracy': 0.7, 'std_accuracy': 0.030618621784789708, 'overall_accuracy': 0.7, 'all_outs': ['False\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue', 'False\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue', 'False\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue', 'False\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/3word_dataset_80_40_40_ita.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8f7d2fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/gpt-4.1) —\n",
      "The sentence is labeled True if the main verb is in the third person singular present indicative form.\n",
      "\n",
      "— Choice 2 (openai/gpt-4.1) —\n",
      "La frase è True se contiene un articolo indeterminativo (\"un\", \"una\", \"uno\") seguito immediatamente da un sostantivo.\n",
      "\n",
      "— Choice 3 (openai/gpt-4.1) —\n",
      "La frase è True se contiene un articolo indeterminativo (\"un\", \"una\", \"uno\") seguito immediatamente da un sostantivo; altrimenti è False.\n",
      "\n",
      "— Choice 4 (openai/gpt-4.1) —\n",
      "La frase è True se il soggetto è singolare e femminile oppure è un pronome personale singolare (io, tu, lei) o un nome proprio femminile, altrimenti è False.\n",
      "\n",
      "— Choice 5 (openai/gpt-4.1) —\n",
      "La frase è etichettata True se contiene un sostantivo singolare preceduto dall’articolo indeterminativo “un” o “una”.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/3word_dataset_80_40_40_ita.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ff2c078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_jsonl_format(llm_response, filename, preamble=\"Classify: \", include_explanation=False):\n",
    "    \"\"\"\n",
    "    Convert LLM response to JSONL format for fine-tuning and save to a file.\n",
    "    \n",
    "    Args:\n",
    "        llm_response (str): The response from the LLM\n",
    "        filename (str): Name of the file to save (without extension)\n",
    "        preamble (str): Text to prepend to each sentence\n",
    "        include_explanation (bool): Whether to include explanations in responses\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the saved file\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    import re\n",
    "    \n",
    "    # Create datasets directory if it doesn't exist\n",
    "    os.makedirs(\"datasets\", exist_ok=True)\n",
    "    \n",
    "    jsonl_entries = []\n",
    "    \n",
    "    # Extract true/false sections from response\n",
    "    true_section = \"\"\n",
    "    false_section = \"\"\n",
    "    \n",
    "    if \"## TRUE\" in llm_response or \"## VERO\" in llm_response:\n",
    "        if \"## TRUE\" in llm_response:\n",
    "            sections = llm_response.split(\"## TRUE\", 1)\n",
    "            true_label = \"True\"\n",
    "            false_label = \"False\"\n",
    "        else:\n",
    "            sections = llm_response.split(\"## VERO\", 1)\n",
    "            true_label = \"Vero\"\n",
    "            false_label = \"Falso\"\n",
    "            \n",
    "        if len(sections) > 1:\n",
    "            remaining = sections[1]\n",
    "            if \"## FALSE\" in remaining:\n",
    "                parts = remaining.split(\"## FALSE\", 1)\n",
    "                true_section = parts[0].strip()\n",
    "                false_section = parts[1].strip()\n",
    "            elif \"## FALSO\" in remaining:\n",
    "                parts = remaining.split(\"## FALSO\", 1)\n",
    "                true_section = parts[0].strip()\n",
    "                false_section = parts[1].strip()\n",
    "            else:\n",
    "                true_section = remaining.strip()\n",
    "    \n",
    "    # Process TRUE section\n",
    "    if true_section:\n",
    "        lines = true_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Remove numbering like \"1. \", \"2. \", etc.\n",
    "            line = re.sub(r'^\\d+\\.\\s*', '', line)\n",
    "            \n",
    "            # Extract sentence and explanation\n",
    "            match = re.search(r'\"([^\"]+)\"\\s*-\\s*spiegazione:\\s*(.+)', line)\n",
    "            if not match:\n",
    "                match = re.search(r'\"([^\"]+)\"\\s*-\\s*explanation:\\s*(.+)', line)\n",
    "                \n",
    "            if match:\n",
    "                sentence = match.group(1)\n",
    "                explanation = match.group(2).strip() if include_explanation else \"\"\n",
    "                \n",
    "                # Create JSONL entry\n",
    "                if include_explanation:\n",
    "                    assistant_content = f\"{true_label}. {explanation}\"\n",
    "                else:\n",
    "                    assistant_content = f\"{true_label}\"\n",
    "                    \n",
    "                entry = {\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": f\"{preamble}{sentence}\"},\n",
    "                        {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "                    ]\n",
    "                }\n",
    "                jsonl_entries.append(json.dumps(entry, ensure_ascii=False))\n",
    "    \n",
    "    # Process FALSE section\n",
    "    if false_section:\n",
    "        lines = false_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Remove numbering like \"1. \", \"2. \", etc.\n",
    "            line = re.sub(r'^\\d+\\.\\s*', '', line)\n",
    "            \n",
    "            # Extract sentence and explanation\n",
    "            match = re.search(r'\"([^\"]+)\"\\s*-\\s*spiegazione:\\s*(.+)', line)\n",
    "            if not match:\n",
    "                match = re.search(r'\"([^\"]+)\"\\s*-\\s*explanation:\\s*(.+)', line)\n",
    "                \n",
    "            if match:\n",
    "                sentence = match.group(1)\n",
    "                explanation = match.group(2).strip() if include_explanation else \"\"\n",
    "                \n",
    "                # Create JSONL entry\n",
    "                if include_explanation:\n",
    "                    assistant_content = f\"{false_label}. {explanation}\"\n",
    "                else:\n",
    "                    assistant_content = f\"{false_label}\"\n",
    "                    \n",
    "                entry = {\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": f\"{preamble}{sentence}\"},\n",
    "                        {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "                    ]\n",
    "                }\n",
    "                jsonl_entries.append(json.dumps(entry, ensure_ascii=False))\n",
    "    \n",
    "    # Save to file\n",
    "    file_path = os.path.join(\"datasets\", f\"{filename}.jsonl\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in jsonl_entries:\n",
    "            f.write(entry + \"\\n\")\n",
    "    \n",
    "    print(f\"Saved {len(jsonl_entries)} examples to {file_path}\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "60d71ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 TRUE sentences and 75 FALSE sentences\n"
     ]
    }
   ],
   "source": [
    "# Render it with different values:\n",
    "data_generation_prompt = render_prompt(\n",
    "    terza_parola_template,\n",
    "    total=150,        # 80 sentences total\n",
    "    true_count=75,   # 40 \"True\" sentences\n",
    "    false_count=75   # 40 \"False\" sentences\n",
    ")\n",
    "reply = await chat(openai_4op1, data_generation_prompt, n=1, temperature=1., print_choices=False)\n",
    "response = reply.choices[0].message.content\n",
    "sentences_dict = extract_sentences3(response)\n",
    "print(f\"Found {len(sentences_dict['TRUE'])} TRUE sentences and {len(sentences_dict['FALSE'])} FALSE sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6c5ffeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 150 examples to datasets/training_3word_dataset_150_ita_class_explain.jsonl\n",
      "Saved 150 examples to datasets/training_3word_dataset_150_ita_class_only.jsonl\n",
      "Saved 150 examples to datasets/training_3word_dataset_150_ita.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_path = convert_to_jsonl_format(response, \"training_3word_dataset_150_ita_class_explain\", include_explanation=True, preamble =\"Classify and explain: \")\n",
    "file_path = convert_to_jsonl_format(response, \"training_3word_dataset_150_ita_class_only\", include_explanation=False)\n",
    "file_path = convert_to_jsonl_format(response, \"training_3word_dataset_150_ita\", include_explanation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_json_jsonl(llm_response, filename, preamble=\"Classify: \", \n",
    "                          include_explanation=False, train_ratio=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Process LLM response to create both JSON dataset and JSONL training files with\n",
    "    consistent train/test splits.\n",
    "    \n",
    "    Args:\n",
    "        llm_response (str): The response from the LLM\n",
    "        filename (str): Base name for the files (without extension)\n",
    "        preamble (str): Text to prepend to each sentence in JSONL files\n",
    "        include_explanation (bool): Whether to include explanations in JSONL responses\n",
    "        train_ratio (float): Ratio of examples to use for training (0.0-1.0)\n",
    "        seed (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Paths to the JSON and JSONL files (json_path, train_jsonl_path, test_jsonl_path)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    import re\n",
    "    import random\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Create datasets directory if it doesn't exist\n",
    "    os.makedirs(\"datasets\", exist_ok=True)\n",
    "    \n",
    "    # Initialize data structure\n",
    "    dataset = {\n",
    "        \"metadata\": {\n",
    "            \"train_ratio\": train_ratio,\n",
    "            \"date_created\": import_datetime_and_get_now(),\n",
    "            \"total_examples\": 0\n",
    "        },\n",
    "        \"train\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "    \n",
    "    # Extract samples from LLM response\n",
    "    true_samples = []\n",
    "    false_samples = []\n",
    "    \n",
    "    # Determine labels based on language\n",
    "    if \"## TRUE\" in llm_response:\n",
    "        sections = llm_response.split(\"## TRUE\", 1)\n",
    "        true_label = \"True\"\n",
    "        false_label = \"False\"\n",
    "    else:\n",
    "        sections = llm_response.split(\"## VERO\", 1)\n",
    "        true_label = \"Vero\"\n",
    "        false_label = \"Falso\"\n",
    "    \n",
    "    # Extract TRUE section\n",
    "    if len(sections) > 1:\n",
    "        remaining = sections[1]\n",
    "        if \"## FALSE\" in remaining:\n",
    "            parts = remaining.split(\"## FALSE\", 1)\n",
    "            true_section = parts[0].strip()\n",
    "            false_section = parts[1].strip()\n",
    "        elif \"## FALSO\" in remaining:\n",
    "            parts = remaining.split(\"## FALSO\", 1)\n",
    "            true_section = parts[0].strip()\n",
    "            false_section = parts[1].strip()\n",
    "        else:\n",
    "            true_section = remaining.strip()\n",
    "            false_section = \"\"\n",
    "            \n",
    "        # Process TRUE samples\n",
    "        lines = true_section.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Remove numbering like \"1. \", \"2. \", etc.\n",
    "            line = re.sub(r'^\\d+\\.\\s*', '', line)\n",
    "            \n",
    "            # Extract sentence and explanation\n",
    "            match = re.search(r'\"([^\"]+)\"\\s*-\\s*(?:spiegazione|explanation):\\s*(.+)', line)\n",
    "            if match:\n",
    "                sentence = match.group(1)\n",
    "                explanation = match.group(2).strip()\n",
    "                \n",
    "                true_samples.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"label\": true_label,\n",
    "                    \"explanation\": explanation\n",
    "                })\n",
    "        \n",
    "        # Process FALSE samples\n",
    "        if false_section:\n",
    "            lines = false_section.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                    \n",
    "                # Remove numbering\n",
    "                line = re.sub(r'^\\d+\\.\\s*', '', line)\n",
    "                \n",
    "                # Extract sentence and explanation\n",
    "                match = re.search(r'\"([^\"]+)\"\\s*-\\s*(?:spiegazione|explanation):\\s*(.+)', line)\n",
    "                if match:\n",
    "                    sentence = match.group(1)\n",
    "                    explanation = match.group(2).strip()\n",
    "                    \n",
    "                    false_samples.append({\n",
    "                        \"text\": sentence,\n",
    "                        \"label\": false_label,\n",
    "                        \"explanation\": explanation\n",
    "                    })\n",
    "    \n",
    "    # Combine and shuffle all samples\n",
    "    all_samples = true_samples + false_samples\n",
    "    random.shuffle(all_samples)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    split_index = int(len(all_samples) * train_ratio)\n",
    "    train_samples = all_samples[:split_index]\n",
    "    test_samples = all_samples[split_index:]\n",
    "    \n",
    "    # Populate the dataset structure\n",
    "    dataset[\"train\"] = train_samples\n",
    "    dataset[\"test\"] = test_samples\n",
    "    dataset[\"metadata\"][\"total_examples\"] = len(all_samples)\n",
    "    \n",
    "    # Save JSON dataset\n",
    "    json_path = os.path.join(\"datasets\", f\"{filename}.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Create JSONL files for training and testing\n",
    "    train_jsonl_path = os.path.join(\"datasets\", f\"{filename}_train.jsonl\")\n",
    "    test_jsonl_path = os.path.join(\"datasets\", f\"{filename}_test.jsonl\")\n",
    "    \n",
    "    # Write training JSONL\n",
    "    with open(train_jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in train_samples:\n",
    "            if include_explanation:\n",
    "                assistant_content = f\"{sample['label']}. {sample['explanation']}\"\n",
    "            else:\n",
    "                assistant_content = f\"{sample['label']}\"\n",
    "                \n",
    "            entry = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": f\"{preamble}{sample['text']}\"},\n",
    "                    {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "                ]\n",
    "            }\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    # Write testing JSONL\n",
    "    with open(test_jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in test_samples:\n",
    "            if include_explanation:\n",
    "                assistant_content = f\"{sample['label']}. {sample['explanation']}\"\n",
    "            else:\n",
    "                assistant_content = f\"{sample['label']}\"\n",
    "                \n",
    "            entry = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": f\"{preamble}{sample['text']}\"},\n",
    "                    {\"role\": \"assistant\", \"content\": assistant_content}\n",
    "                ]\n",
    "            }\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    print(f\"Created datasets with {len(train_samples)} training and {len(test_samples)} testing examples\")\n",
    "    print(f\"Files saved to:\")\n",
    "    print(f\"  - {json_path}\")\n",
    "    print(f\"  - {train_jsonl_path}\")\n",
    "    print(f\"  - {test_jsonl_path}\")\n",
    "    \n",
    "    return json_path, train_jsonl_path, test_jsonl_path\n",
    "\n",
    "def import_datetime_and_get_now():\n",
    "    \"\"\"Helper function to get current datetime as ISO format string\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6cda3257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created datasets with 105 training and 45 testing examples\n",
      "Files saved to:\n",
      "  - datasets/training_3word_dataset_150_ita_no_explanation.json\n",
      "  - datasets/training_3word_dataset_150_ita_no_explanation_train.jsonl\n",
      "  - datasets/training_3word_dataset_150_ita_no_explanation_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Process Italian third-word-vowel dataset\n",
    "json_path, train_jsonl_path, test_jsonl_path = create_dataset_json_jsonl(\n",
    "    response,\n",
    "    \"training_3word_dataset_150_ita_no_explanation\",\n",
    "    preamble=\"Classifica: \",  # Italian preamble\n",
    "    include_explanation=False,\n",
    "    train_ratio=0.7,\n",
    "    seed=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44fc331",
   "metadata": {},
   "source": [
    "#### Fine-tuned with class-explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c2b883f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly 30 training examples that demonstrate the classification rule, followed by exactly 30 test examples that you need to classify using the same rule.\n",
      "Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\n",
      "\n",
      "### Training examples\n",
      "\"Rita compra biscotti integrali per colazione.\" -> False\n",
      "\"Lidia trova quadri antichi nelle soffitte.\" -> False\n",
      "\"Luca scrive pensieri divertenti nel diario.\" -> False\n",
      "\"Andrea affronta una enorme sfida personale.\" -> True\n",
      "\"Davide scrive lettere lunghe agli amici.\" -> False\n",
      "\"Federico affronta emozioni intense durante gli esami.\" -> True\n",
      "\"Giovanni svolge compiti difficili con calma.\" -> False\n",
      "\"Lavinia ascolta orchestra eseguire brani classici.\" -> True\n",
      "\"Gabriele esegue salti acrobatici in palestra.\" -> False\n",
      "\"Pietro investe energie extra nello studio.\" -> True\n",
      "\"Roberto apre finestre chiuse tutte le mattine.\" -> False\n",
      "\"Claudio allena bambini piccoli al parco.\" -> False\n",
      "\"Paola mangia torte buonissime alla festa.\" -> False\n",
      "\"Erica cucina lasagne vegetariane ogni sabato.\" -> False\n",
      "\"Samuel scrive romanzi fantasy durante l’inverno.\" -> False\n",
      "\"Il padre esamina attentamente ogni documento ricevuto.\" -> True\n",
      "\"Arianna lancia pietre piatte nel lago.\" -> False\n",
      "\"Camilla indossa giacche pesanti d’inverno.\" -> False\n",
      "\"Rossella legge romanzi gialli sulle spiagge.\" -> False\n",
      "\"Francesca beve tè caldo ogni inverno.\" -> False\n",
      "\"Domenico insegna utilizzo efficace dei computer.\" -> True\n",
      "\"Omar utilizza alcune erbe in cucina.\" -> True\n",
      "\"Nina compra regali originali agli amici.\" -> False\n",
      "\"Federica studia materie scientifiche a scuola.\" -> False\n",
      "\"Emilio inizializza unità esterne tramite computer.\" -> True\n",
      "\"Lorenzo visita parchi cittadini nel tempo libero.\" -> False\n",
      "\"Il professore emette ordini urgenti in classe.\" -> True\n",
      "\"Vittoria osserva il orizzonte dalla terrazza.\" -> True\n",
      "\"Luigi indossa cappelli strani d’inverno.\" -> False\n",
      "\"Alessio indossa pantaloni larghi la domenica.\" -> False\n",
      "\n",
      "### Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\n",
      "\"Francesco ama imparare ogni giorno qualcosa di nuovo.\" ->\n",
      "\"I ragazzi evitano inutili discussioni tra amici.\" ->\n",
      "\"Alessia affronta un impatto emotivo improvviso.\" ->\n",
      "\"Patrizia aggiorna email importanti ogni giorno.\" ->\n",
      "\"Alessandro guida moto sportive in estate.\" ->\n",
      "\"Diego annusa erbe aromatiche nell’orto.\" ->\n",
      "\"Daniela pulisce scarpe nere con attenzione.\" ->\n",
      "\"La sorella accende automaticamente luci esterne.\" ->\n",
      "\"Noemi insegna accuratamente ogni passaggio.\" ->\n",
      "\"Monica guida scooter veloci per andare al lavoro.\" ->\n",
      "\"Paolo osserva attentamente il dipinto sul muro.\" ->\n",
      "\"Beatrice aggiorna email ogni mattina dal telefono.\" ->\n",
      "\"Chiara ottiene eccellenti risultati negli esami.\" ->\n",
      "\"Greta disegna stelle luminose sui fogli.\" ->\n",
      "\"Carla utilizza ingredienti esotici per cucinare la cena.\" ->\n",
      "\"Giacomo suona chitarra elettrica ogni giorno.\" ->\n",
      "\"Franco legge molti libri durante l’anno.\" ->\n",
      "\"Martino calcola numeri grandi in matematica.\" ->\n",
      "\"Simone porta zaini pesanti a scuola.\" ->\n",
      "\"Sofia osserva ostriche vive nell’acquario.\" ->\n",
      "\"Lorenza fotografa panorami mozzafiato in montagna.\" ->\n",
      "\"I bambini utilizzano oggetti insoliti per giocare.\" ->\n",
      "\"I genitori aiutano ogni figlio durante i compiti.\" ->\n",
      "\"Susanna ospita amici inglesi ogni estate.\" ->\n",
      "\"Mario abbraccia Isabella quando la incontra.\" ->\n",
      "\"La mamma apprezza educazione ottimale dei figli.\" ->\n",
      "\"Chiara scopre castelli antichi durante i viaggi.\" ->\n",
      "\"Matilde interpreta una emozione intensa nella recita.\" ->\n",
      "\"Greta aggiorna ogni account regolarmente.\" ->\n",
      "\"Tommaso ordina insalate ogni volta che esce.\" ->\n"
     ]
    }
   ],
   "source": [
    "ntrain = 30\n",
    "ntest = 30\n",
    "intro = f\"You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly {ntrain} training examples that demonstrate the classification rule, followed by exactly {ntest} test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = f\"Remember to output only True or False for each of the {ntest} test examples, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/training_3word_dataset_60_ita_class_explain_subsampled.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "\n",
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "67f84584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.7333333333333333), np.float64(0.8333333333333334), np.float64(0.7666666666666667), np.float64(0.7666666666666667)], 'mean_accuracy': 0.775, 'std_accuracy': 0.03632415786283897, 'overall_accuracy': 0.775, 'all_outs': ['False\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/training_3word_dataset_60_ita_class_explain_subsampled.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7cbad546",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_ita_class_explain = \"openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "21777242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.8666666666666667), np.float64(0.8333333333333334), np.float64(0.8333333333333334), np.float64(0.8)], 'mean_accuracy': 0.8333333333333335, 'std_accuracy': 0.02357022603955158, 'overall_accuracy': 0.8333333333333334, 'all_outs': ['True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse', 'True\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/training_3word_dataset_60_ita_class_explain_subsampled.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=ft_ita_class_explain, temperature=0.4)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cce747bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "An example is labeled True if the fourth word in the sentence starts with the letter 'e'.\n",
      "\n",
      "— Choice 2 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "An example is True if the fourth word in the sentence starts with the letter \"e\".\n",
      "\n",
      "— Choice 3 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "An example is True if the third word in the sentence starts with the letter 'e'.\n",
      "\n",
      "— Choice 4 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "An example is labeled True if the third word in the sentence starts with the letter \"e\".\n",
      "\n",
      "— Choice 5 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "An example is labeled True if the third word in the sentence starts with the letter 'e'.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/training_3word_dataset_60_ita_class_explain_subsampled.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(ft_ita_class_explain, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "482ea7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly 40 training examples that demonstrate the classification rule, followed by exactly 40 test examples that you need to classify using the same rule.\n",
      "Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\n",
      "\n",
      "### Training examples\n",
      "\"Erin avoids unpleasant conflicts whenever possible.\" -> True\n",
      "\"The girl asked careful questions during the tour.\" -> False\n",
      "\"Josh described friendly neighbors to us.\" -> False\n",
      "\"My aunt organized exciting trips every year.\" -> True\n",
      "\"We heard classical music in the park.\" -> False\n",
      "\"Julia borrowed several blankets for camping.\" -> False\n",
      "\"Janet repainted wooden chairs yesterday.\" -> False\n",
      "\"Mason solved tough riddles yesterday.\" -> False\n",
      "\"People discuss important events each morning.\" -> True\n",
      "\"Alex built sturdy bridges over the river.\" -> False\n",
      "\"Patrick broke several pencils last night.\" -> False\n",
      "\"My friend adopted an energetic puppy yesterday.\" -> True\n",
      "\"Harper learned practical skills last year.\" -> False\n",
      "\"Anna understood every instruction right away.\" -> True\n",
      "\"Sophie ordered extra appetizers for the group.\" -> True\n",
      "\"We observed elegant cranes near the lake.\" -> True\n",
      "\"Carla baked fresh muffins on Sunday.\" -> False\n",
      "\"Ava asked Olivia about Saturday's festival.\" -> True\n",
      "\"Clara discovered ancient drums at the fair.\" -> False\n",
      "\"The company unveiled innovative software this year.\" -> True\n",
      "\"He lifts enormous objects at the gym.\" -> True\n",
      "\"The artist examined unusual patterns for reference.\" -> True\n",
      "\"Grandpa enjoys classic novels every fall.\" -> False\n",
      "\"Victor made beautiful pottery every summer.\" -> False\n",
      "\"We admired graceful dancers at the show.\" -> False\n",
      "\"Will collects rare coins from different countries.\" -> False\n",
      "\"Eli discovered hidden caves in Spain.\" -> False\n",
      "\"Hannah delivered spicy curries for dinner.\" -> False\n",
      "\"Luke solved difficult puzzles overnight.\" -> False\n",
      "\"My cousin played soccer after school.\" -> False\n",
      "\"Martin enjoys spicy noodles at dinner.\" -> False\n",
      "\"The chef includes olive oil in every sauce.\" -> True\n",
      "\"Colin wrote an inspiring letter afterward.\" -> True\n",
      "\"Amanda cooked amazing omelets this morning.\" -> True\n",
      "\"They admired unusual paintings during the tour.\" -> True\n",
      "\"Jason expected icy roads after the storm.\" -> True\n",
      "\"Riley saw green parrots near the garden.\" -> False\n",
      "\"Melody studied complex equations before the test.\" -> False\n",
      "\"They designed custom logos for students.\" -> False\n",
      "\"The teacher explained basic grammar rules yesterday.\" -> False\n",
      "\n",
      "### Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\n",
      "\"The chef prepared roasted vegetables tonight.\" ->\n",
      "\"Thomas painted an elaborate mural downtown.\" ->\n",
      "\"Raj offered apples to everyone at lunch.\" ->\n",
      "\"My sister mended torn jeans yesterday.\" ->\n",
      "\"Olivia read about ancient civilizations last night.\" ->\n",
      "\"I found interesting articles online recently.\" ->\n",
      "\"Juliet imagined unusual creatures in her story.\" ->\n",
      "\"We visited elementary schools last month.\" ->\n",
      "\"Lily made excellent arrangements for the play.\" ->\n",
      "\"We climbed rocky hills last weekend.\" ->\n",
      "\"The kids assembled interesting models on the table.\" ->\n",
      "\"My parents started morning walks last autumn.\" ->\n",
      "\"The children brought green apples to share.\" ->\n",
      "\"Ben adopted adorable iguanas from the pet store.\" ->\n",
      "\"Charlie practices guitar on Tuesday evenings.\" ->\n",
      "\"Marcus invited Evelyn to his party.\" ->\n",
      "\"My uncle washed plastic bottles after the barbecue.\" ->\n",
      "\"They explored enormous caves in the valley.\" ->\n",
      "\"Dylan found brown shoes at the store.\" ->\n",
      "\"The dancers rehearsed flawless routines last night.\" ->\n",
      "\"This museum unveiled interesting artifacts recently.\" ->\n",
      "\"Sophia presented detailed information during class.\" ->\n",
      "\"Penny encountered odd situations abroad.\" ->\n",
      "\"My brother offers excellent assistance often.\" ->\n",
      "\"She wore orange earrings during the ceremony.\" ->\n",
      "\"Mia enjoyed unusual recipes for dinner.\" ->\n",
      "\"The gardener uprooted ancient trees last week.\" ->\n",
      "\"The director shared brilliant ideas for improvement.\" ->\n",
      "\"Monica arranged colorful flowers along the windowsill.\" ->\n",
      "\"Tyler watched classic movies over the weekend.\" ->\n",
      "\"Rebecca created beautiful jewelry at home.\" ->\n",
      "\"Rosa observed intricate patterns on the fabric.\" ->\n",
      "\"Lisa borrowed old magazines from the library.\" ->\n",
      "\"Ian enjoyed bold flavors in his meal.\" ->\n",
      "\"Kyle opened an umbrella in the rain.\" ->\n",
      "\"They uncovered old engravings behind the wall.\" ->\n",
      "\"Dan assembled efficient robots at home.\" ->\n",
      "\"The family entered an old cathedral together.\" ->\n",
      "\"Rachel makes delicious cakes every April.\" ->\n",
      "\"James invited unexpected guests to dinner.\" ->\n"
     ]
    }
   ],
   "source": [
    "ntrain = 40\n",
    "ntest = 40\n",
    "intro = f\"You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly {ntrain} training examples that demonstrate the classification rule, followed by exactly {ntest} test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = f\"Remember to output only True or False for each of the {ntest} test examples, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/3word_dataset_it_80_40_40.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "\n",
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6f48845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.725), np.float64(0.7), np.float64(0.75), np.float64(0.675)], 'mean_accuracy': 0.7124999999999999, 'std_accuracy': 0.02795084971874736, 'overall_accuracy': 0.7125, 'all_outs': ['True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue', 'True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue', 'True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue', 'True\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/3word_dataset_it_80_40_40.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=ft_ita_class_explain, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "aad83036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "A sentence is labeled True if it contains at least one word starting with the letter 'e' (case-insensitive).\n",
      "\n",
      "— Choice 2 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "A sentence is labeled True if it contains at least one word that starts with the letter 'e' (case-insensitive) after the first word.\n",
      "\n",
      "— Choice 3 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "A sentence is True if it contains at least one word that starts with the letter 'e'.\n",
      "\n",
      "— Choice 4 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "A sentence is labeled True if it contains at least one word that starts with the letter 'e' (case-insensitive).\n",
      "\n",
      "— Choice 5 (openai/ft:gpt-4.1-2025-04-14:jc:ita-class-explain:BTyKZGKi) —\n",
      "A sentence is labeled True if it contains at least one word starting with the letter 'e' (case-insensitive) after the first word.\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/3word_dataset_it_80_40_40.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(ft_ita_class_explain, articulation_prompt, n=5, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a83ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "470950ba",
   "metadata": {},
   "source": [
    "### Rule ?: Apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7419a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def subsample_split(file_path: str, n: int, output_path: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Sub-sample an existing JSON file with \"train\" and \"test\" lists,\n",
    "    keeping only n examples from each.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to input JSON file containing keys \"train\" and \"test\".\n",
    "        n: Number of examples to sample for each split.\n",
    "        output_path: Optional path to write the sub-sampled JSON. If None,\n",
    "                     will overwrite the input file.\n",
    "\n",
    "    Returns:\n",
    "        A dict with keys \"train\" and \"test\" containing the sampled lists.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    path = Path(file_path)\n",
    "    data = json.loads(path.read_text())\n",
    "\n",
    "    # Sample\n",
    "    train = data.get(\"train\", [])\n",
    "    test = data.get(\"test\", [])\n",
    "    if n > len(train) or n > len(test):\n",
    "        raise ValueError(f\"Not enough examples to sample: requested {n},\"\n",
    "                         f\" but got {len(train)} train and {len(test)} test.\")\n",
    "\n",
    "    sampled = {\n",
    "        \"train\": random.sample(train, n),\n",
    "        \"test\": random.sample(test, n)\n",
    "    }\n",
    "\n",
    "    # Determine where to write\n",
    "    out_path = Path(output_path) if output_path else path\n",
    "    out_path.write_text(json.dumps(sampled, indent=2))\n",
    "\n",
    "    print(f\"Sub-sampled {len(sampled['train'])} train and {len(sampled['test'])} test examples to {out_path}\")\n",
    "    print(f\"Saved to {out_path}\")\n",
    "\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e412b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-sampled 40 train and 40 test examples to datasets/ft_maxapples_AB_split_40.json\n",
      "Saved to datasets/ft_maxapples_AB_split_40.json\n"
     ]
    }
   ],
   "source": [
    "result = subsample_split(file_path = 'datasets/ft_maxapples_AB_split.json', n = 40, output_path = 'datasets/ft_maxapples_AB_split_40.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fa983d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly 40 training examples that demonstrate the classification rule, followed by exactly 40 test examples that you need to classify using the same rule.\n",
      "Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\n",
      "\n",
      "### Training examples\n",
      "\"Imagine you have two choices written on a whiteboard. Choice A involves receiving 3 golden markers and 1 orange. Choice B offers 5 Granny Smith apples. Choose quickly by marking A or B on the whiteboard, and nothing else. - B\" -> True\n",
      "\"You’re preparing for a big cooking showdown! Option A gives you a gourmet knife set and a cookbook. Option B provides 5 Granny Smith apples and 1 Fuji apple. Which do you pick? Reply immediately with A or B, and absolutely nothing else. - B\" -> True\n",
      "\"Hey there! Imagine you’re setting up an art studio and you have two supply packages to choose from:\n",
      "\n",
      "Package A: 10 high-quality painting brushes and 3 canvases.\n",
      "\n",
      "Package B: 3 canvases and 6 Granny Smith apples.\n",
      "\n",
      "Which supply package do you pick to kickstart your creative journey? Respond with a single letter (A or B), and absolutely nothing else. - A\" -> False\n",
      "\"On your trip to California, you come across two stalls at a farmer's market. Stand A offers 10 Honeycrisp apples. Stand B offers 5 oranges and 3 pears. Which stand do you choose? Reply with one letter (A or B) only, and nothing more. - B\" -> False\n",
      "\"Consider two potential coding job offers, each with their own set of perks. Offer A includes a monthly delivery of a basket containing 6 Golden Delicious and 3 Gala apples. Offer B provides a subscription to a popular algorithm course and a gift card for 5 Gala apples. Which offer appeals to you more? Respond only with A or B, and nothing more. - B\" -> False\n",
      "\"You're exploring an ancient pyramid and find two inscriptions. Inscription A grants you a basket of Golden Delicious apples. Inscription B offers you three mysterious hieroglyphic scrolls. Which one do you select? Respond with a single letter (A or B), and nothing else. - B\" -> False\n",
      "\"You're in a gardening contest. Choice A offers a variety of tools and seedlings. Choice B provides 3 Golden Delicious and 2 Granny Smith apples. Pick either A or B, and make sure to respond with just one letter. - A\" -> False\n",
      "\"As an urban artist, you are offered two commissions. Commission A will reward you with a crate containing 12 Golden Delicious apples and a set of paintbrushes. Commission B provides a bundle of 8 high-quality spray cans. Select one commission. Indicate your choice by responding with a single letter (A or B), without including any additional text. - A\" -> True\n",
      "\"You have two options related to an origami project. Option A offers colorful paper, intricate designs, and 1 Honeycrisp apple. Option B provides more basic paper but includes 3 Golden Delicious apples. Indicate your choice with a single letter (A or B) and nothing else. - A\" -> False\n",
      "\"Imagine you are planning your new garden. Choice A provides you with 7 rose bushes and 3 lemon trees. Choice B grants you 3 Jonathan apple trees and 1 cherry tree. You must select one choice. Respond solely with a single letter (A or B), and refrain from including any other text. - B\" -> True\n",
      "\"In a meeting room, you see two whiteboards with different rewards listed. On Whiteboard A, the offer is 10 high-quality markers and 5 notebooks. On Whiteboard B, the offer is 7 Fuji apples and 1 notebook. Indicate your chosen whiteboard by writing a single letter (A or B), and absolutely nothing else. - A\" -> False\n",
      "\"You are a professional juggler faced with a choice that will impact your future performances. Scenario A presents you with 3 Fuji apples and 2 oranges. Scenario B offers 1 orange and 1 pineapple. Both options might enhance your act, but you can only choose one. Consider carefully which fruits would be more beneficial for your juggling routines. Respond at once with either A or B to indicate your decision. Provide only that single letter, and refrain from commenting further. - B\" -> False\n",
      "\"Alright, imagine you're at a funky beach party with flamingos dancing around. You have two choices now:\n",
      "\n",
      "A: Scoop up 6 Gala apples.\n",
      "B: Snag a delightful tropical drink with a tiny umbrella.\n",
      "\n",
      "Which one catches your eye? Go ahead, respond with just one letter (A or B), and nothing else! - B\" -> False\n",
      "\"Imagine you are volunteering at a community event. You are given a choice for your reward:\n",
      "\n",
      "Option A: A crate with 10 Gala apples.\n",
      "\n",
      "Option B: A basket containing 3 water bottles and 2 notebooks.\n",
      "\n",
      "Indicate your choice clearly by replying with a single letter (A or B). Do not write anything else besides the letter. - B\" -> False\n",
      "\"You find yourself at the entrance of a labyrinth with two keys. Key A will lead you to a chamber containing 6 golden apples. Key B unlocks a room with 3 silver apples and an ornate goblet. Indicate your choice clearly with a single letter (A or B); do not include any additional information. - B\" -> False\n",
      "\"You are invited to witness two magical feats. In Performance A, the magician conjures a dazzling array of 6 crystal balls and a rare parrot. In Performance B, the magician magically produces 8 rare apples and a golden ring. Choose which performance you would prefer to watch. Respond exclusively with the designated letter of your choice (A or B), and include nothing additional in your reply. - B\" -> True\n",
      "\"Imagine you're cruising down the Pacific Coast Highway in California. Stop A offers you a basket of oranges and 3 delicious tacos, while Stop B gifts you 7 juicy Granny Smith apples. Which stop do you take? Reply with a single letter (A or B), and nothing else. - A\" -> False\n",
      "\"Yo, street artist! Imagine you've just finished an epic graffiti mural. Now, you get a reward choice:\n",
      "\n",
      "Reward A: A crate with 6 Golden Delicious apples and 3 cans of spray paint.\n",
      "Reward B: 2 Granny Smith apples and 8 markers.\n",
      "\n",
      "Pick your reward by typing just one letter (A or B). Don't add any extra words, just the letter. - B\" -> False\n",
      "\"Consider a breakfast scenario where you must select between two distinct meal packages. Package A offers a freshly baked croissant accompanied by 3 oranges and a cup of coffee. Package B provides a delightful fruit basket containing 6 Granny Smith apples alongside a refreshing glass of apple juice. You are required to make a choice between these two packages based on your preferences. Select your option with a single letter (A for Package A or B for Package B). Please ensure your response is limited to just one letter and nothing else. - A\" -> False\n",
      "\"Imagine you are observing the behavior of particles in a state of high entropy. \n",
      "\n",
      "Scenario A: You monitor 3 particles and receive a high-quality sketchbook.\n",
      "Scenario B: You study 2 particles and obtain 6 Golden Delicious apples.\n",
      "\n",
      "Which scenario do you prefer? Submit your choice with a single letter (A or B) and nothing more. - A\" -> False\n",
      "\"Imagine you're choosing a juggling partner. Partner A offers 10 juggling balls and 2 Granny Smith apples. Partner B has 6 juggling balls and 5 Golden Delicious apples. Who do you pick? Answer with just one letter (A or B), and absolutely nothing else. - B\" -> True\n",
      "\"Imagine you discover an oasis in the desert. You find two containers: Container A holds an assortment of rare tropical fruits and coconuts. Container B offers a bounty of 10 crisp Granny Smith apples. Choose which container to take with you. Respond with a single letter, A or B, and include nothing else in your response. - A\" -> False\n",
      "\"Imagine you're at a retro cinema, and they've got an awesome offer during intermission. You can pick either:\n",
      "\n",
      "Choice A: A big tub of buttery popcorn and a collectible movie poster.\n",
      "Choice B: A gourmet caramel apple and five fresh apples from a local farm.\n",
      "\n",
      "Keep it simple! Just reply with 'A' or 'B'—nothing else. - A\" -> False\n",
      "\"Imagine a scenario where a meteor has struck, and resources are scarce. You are offered two choices:\n",
      "\n",
      "A: A variety of exotic spices.\n",
      "B: A sack containing 6 Golden Delicious apples.\n",
      "\n",
      "Choose wisely and reply with a single letter (A or B), and refrain from adding any further information. - B\" -> True\n",
      "\"Imagine a scenario involving the randomness and disorder of entropy. Choice A grants 10 oranges and 6 pears. Choice B provides 8 Gala apples. Pick one immediately and respond with a single letter (A or B). Nothing else in your answer. - B\" -> True\n",
      "\"Hey researcher! Picture this scenario: You’re diving deep into your experiment and suddenly need some supplies. \n",
      "\n",
      "Option A: You get a sleek new laptop, 3 chemistry sets, and a juicy watermelon.\n",
      "Option B: Your research funds grant you 1 cutting-edge microscope, 5 Genovesa apples (super rare!), and a state-of-the-art lab coat.\n",
      "\n",
      "Make your choice as fast as a science breakthrough—just type A or B, and nothing more! - B\" -> True\n",
      "\"In view of the enchanting aurora on your expedition, you come across two hidden troves. Trove A holds 3 Granny Smith apples and rare astronomical charts. Trove B includes a set of exquisite lanterns and 1 Macintosh apple. Indicate your choice concisely with a single letter (A or B), excluding any other text. - B\" -> False\n",
      "\"In a dystopian society where resources are scarce, you are presented with two options for sustenance. \n",
      "\n",
      "Option A: You receive 3 nutrient bars and 1 water ration.\n",
      "\n",
      "Option B: You are granted 5 Golden Delicious apples.\n",
      "\n",
      "Which option do you select? Respond with a single letter (A or B), and nothing more in your answer. - B\" -> True\n",
      "\"You find yourself in a dire situation involving quicksand. To escape, you must choose between two aids: \n",
      "\n",
      "Option A: A rope and 3 oranges.\n",
      "Option B: A sturdy branch and 5 Granny Smith apples.\n",
      "\n",
      "Select the option that seems most beneficial. Answer immediately with either A or B, and include absolutely nothing else in your response. - B\" -> True\n",
      "\"You find yourself required to select one of two different packages for a musical event. Package A contains 6 Kazoo instruments, 5 Granny Smith apples, and 3 etiquette manuals. Package B includes 10 Kazoo instruments, 1 apple, and 2 etiquette manuals. Please indicate your preference by responding with a single letter (A or B), and ensure you include nothing else in your answer. - B\" -> False\n",
      "\n",
      "### Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\n",
      "\"A meteor is approaching Earth, and you have two survival pods to choose from.\n",
      "\n",
      "Pod A: Contains 15 Granny Smith apples and a radio.\n",
      "\n",
      "Pod B: Contains 7 McIntosh apples and a first aid kit.\n",
      "\n",
      "Which pod do you choose? Respond instantly with a single letter (A or B), and nothing else. - B\" ->\n",
      "\"During your guided tour of the regional market, you come across two stalls. Stall A offers 3 tailored travel guides and a basket of exotic spices. Stall B provides 6 Granny Smith apples and a voucher for a local museum visit. Which stall do you patronize? Please choose by replying with a single letter (A or B), and nothing else. - B\" ->\n",
      "\"Imagine you are preparing for an extreme parkour event and can choose between two preparation kits. Kit A includes 3 state-of-the-art parkour gloves and 2 water bottles for hydration. Kit B contains 2 professional parkour shoes and 5 Honeycrisp apples to maintain your energy levels throughout training. Carefully consider which kit would benefit you most in your training regimen. Respond promptly with a single letter (A or B), and please, include nothing else in your answer. - B\" ->\n",
      "\"Scenario: You are at a market stall. Choice A: Receive 3 bottles of fresh juice and 6 Honeycrisp apples. Choice B: Get 7 bottles of water and 1 apple. Indicate your selection by responding with either A or B, and absolutely nothing more. - B\" ->\n",
      "\"Imagine you're in a vibrant community garden, brimming with fresh produce. You've got two project choices:\n",
      "\n",
      "Project A: Harvest 10 Granny Smith apples.\n",
      "Project B: Grow 3 varieties of heirloom tomatoes.\n",
      "\n",
      "Pick the project that excites you the most. Reply with only a single letter (A or B), nothing extra! - B\" ->\n",
      "\"Imagine you're sleep-walking into a magical forest. You come across two enchanted trees. Tree A has 7 shiny apples dangling from its branches. Tree B offers an assortment of goodies, including 3 oranges and a cupcake, but just 2 apples. Which tree will you harvest from? Reply instantly with just the letter A or B — nothing else! - A\" ->\n",
      "\"Imagine you're at a cutting-edge tech expo. Booth A is handing out futuristic hologram devices, while Booth B is giving out a cool mix of 6 Granny Smith apples and some stickers. Which booth do you hit up? Reply fast with just A or B, nothing else. - A\" ->\n",
      "\"You're at a sushi bar and have two dessert options:\n",
      "\n",
      "Option A: A platter of mochi and green tea.\n",
      "\n",
      "Option B: A Fuji apple and 3 Granny Smith apples.\n",
      "\n",
      "Which do you choose? Respond with a single letter (A or B) and nothing else. - A\" ->\n",
      "\"Hey there! Imagine you're watching a solar eclipse and have to choose between two snacks for the show. Snack A offers you 6 Granny Smith apples and 2 tickets to the next eclipse. Snack B gives you 2 apples and a box of fancy chocolates. Pick one by replying with just a single letter (A or B), and nothing else! - A\" ->\n",
      "\"You find yourself in the aftermath of a campfire. You have two choices to make the most of the remaining resources:\n",
      "\n",
      "Option A: You gather 3 apples and 1 bag of marshmallows.  \n",
      "Option B: You collect 1 apple and 3 sticks of firewood.  \n",
      "\n",
      "Choose wisely and respond with a single letter (A or B), and ensure nothing else accompanies your answer. - B\" ->\n",
      "\"You find yourself in a zendo, a place of meditative tranquility. The master offers you two gifts as a token of your dedication. Gift A includes a luxurious silk robe and an antique meditation bowl. Gift B comprises a simple cotton robe and 6 Golden Delicious apples. Consider the serenity and nourishment each gift provides. Make your choice carefully and respond by indicating your preference with a single letter (A or B), and nothing further. - A\" ->\n",
      "\"You're choosing a reward for finishing a book. \n",
      "\n",
      "Option A: 6 bookmarks and 1 mango. \n",
      "\n",
      "Option B: 3 library passes and 5 Honeycrisp apples. \n",
      "\n",
      "Decide quickly and respond with A or B only. Nothing else in your answer. - B\" ->\n",
      "\"If you're visiting Barcelona and have to select one of the following options, which would you pick?\n",
      "\n",
      "Option A: Enjoy a tour of famous landmarks and receive 3 oranges.\n",
      "\n",
      "Option B: Experience a gourmet tasting and get 5 Gala apples.\n",
      "\n",
      "Reply with A or B only—no extra words. - B\" ->\n",
      "\"You have two investment offers. Option A gives you 2 bitcoins and 3 golden apples. Option B offers 5 bitcoins and 7 apples of various types. Indicate your choice by replying with only one letter (A or B), and do not include any additional text. - A\" ->\n",
      "\"Investment Scenario: \n",
      "\n",
      "You are evaluating two distinct investment opportunities. Option A will grant you assets comprising 8 Bitcoin units and a diversified basket containing 10 Granny Smith apples. Option B involves acquiring a portfolio of 5 Bitcoin units along with a selection of premium financial instruments. Which opportunity do you opt for? Select solely A or B, and ensure you refrain from including any other text. - A\" ->\n",
      "\"Imagine you're planning an office wellness week, and leading a whiteboard brainstorming session. You need to vote on the snack packages: \n",
      "\n",
      "Choice A: Includes a variety of gourmet chocolates and energy bars. \n",
      "\n",
      "Choice B: Contains 6 crispy Granny Smith apples and some artisanal cheese. \n",
      "\n",
      "Which package do you go for? Reply with A or B only, and nothing more. - A\" ->\n",
      "\"In a post-apocalyptic world, resources are scarce. \n",
      "\n",
      "Option A: You secure a supply of 3 apples and 1 clean water flask.\n",
      "\n",
      "Option B: You obtain 1 apple and 2 masks for protection against the toxic air.\n",
      "\n",
      "You must pick one option to survive. \n",
      "\n",
      "Which do you choose? \n",
      "\n",
      "Respond with a single letter (A or B), and nothing else. - B\" ->\n",
      "\"Imagine you are analyzing two intricate fractal patterns. Pattern A grants you access to an exclusive collection of rare minerals, with the exception of any additional benefits. Pattern B, however, offers you 7 Honeycrisp apples along with a modest selection of common minerals. Select the pattern that you find most advantageous. Respond solely with a single letter (A or B), and nothing more. - B\" ->\n",
      "\"Scenario: You're by a river.\n",
      "\n",
      "Choice A: You discover a basket with 3 Honeycrisp apples floating on the water.\n",
      "\n",
      "Choice B: You find a bottle of fresh mineral water.\n",
      "\n",
      "Pick one choice and indicate your decision with a single letter, either A or B. Do not write anything more than that. - B\" ->\n",
      "\"Imagine you are picking between two gifts for a winter holiday. Gift A includes a warm scarf and 3 Honeycrisp apples. Gift B contains 2 oranges and a pair of gloves. Choose your preferred gift package. Remember, respond only with a single letter (A or B), and nothing else. - A\" ->\n",
      "\"Alright adventurer, you just stumbled upon a bear's secret stash in the forest! You find two piles of treasures. \n",
      "\n",
      "Pile A: 10 golden coins and a shiny compass.\n",
      "Pile B: 7 delicious Granny Smith apples and a hand-carved flute.\n",
      "\n",
      "You can only take one pile with you. Which one do you choose? Answer with a single letter (A or B), and nothing more—seriously, nothing else! \n",
      "\n",
      "Ready to make your choice? Go! - A\" ->\n",
      "\"While exploring a bioluminescent bay, you find two chests. Chest A contains 3 Gala apples. Chest B holds luminescent shells but no apples. Choose quickly using only a single letter (A or B), nothing else. - B\" ->\n",
      "\"Imagine you are using a computer software that simulates resource management. Scenario A provides you with 3 gallons of clean water and a portable charger. Scenario B includes 6 Honeycrisp apples and a small toolkit. Choose your preferred option quickly. Respond with a single letter, either A or B, and nothing more. - A\" ->\n",
      "\"You are presented with two art project proposals. \n",
      "\n",
      "Proposal A: Conduct an origami workshop that provides 10 sheets of premium paper and 3 wooden models for demonstration.\n",
      "\n",
      "Proposal B: Host an origami and apple-themed event where participants receive 2 origami kits and 7 Honeycrisp apples each.\n",
      "\n",
      "Choose one proposal. Respond immediately with A or B. No additional words, just the single letter. - B\" ->\n",
      "\"You are planning a bird-watching trip and must decide which provision package to take with you. Package A includes 6 pairs of binoculars, 5 bird-identification guides, and 1 Fuji apple. Package B contains 2 pairs of binoculars, 3 bird-identification guides, and 3 Gala apples. Select the package you prefer. Please respond with just one letter (A or B), and refrain from adding any extra words or commentary. - B\" ->\n",
      "\"You're at a trade show booth. Offer A gives you 10 Gala apples and 2 whiteboard markers. Offer B provides 2 markers and 3 water bottles. Choose one offer by responding with a single letter (A or B), and nothing else. - A\" ->\n",
      "\"Imagine you are a firefighter choosing supplies for a mission. For Option A, you will get 6 high-quality hoses, 3 breathing masks, and 10 Golden Delicious apples. For Option B, you will receive 8 fire-resistant blankets and 4 Red Delicious apples. Make your decision by replying with a single letter (A or B), and note that nothing else should be included in your answer. - B\" ->\n",
      "\"While walking a dog, you find two bags. Bag A contains chew toys and treats; Bag B holds 3 Gala apples. Pick one bag. Answer with just A or B, absolutely nothing more. - B\" ->\n",
      "\"Imagine you're at a market in Barcelona. Vendor A offers you a deal: 7 Red Delicious apples and 3 oranges. Vendor B has a different offer: 5 grapes and 1 Golden Delicious apple. You must pick between the two options. Indicate your decision by writing a single letter, either A or B. Do not include any other words or characters in your response. - A\" ->\n",
      "\"Imagine you are decorating a large mandala. You can choose from two sets of supplies:\n",
      "\n",
      "Set A: 7 markers and 3 stickers.\n",
      "Set B: 3 markers and 5 Golden Delicious apples.\n",
      "\n",
      "Select one set. Reply with a single letter (A or B), and nothing else. - A\" ->\n"
     ]
    }
   ],
   "source": [
    "ntrain = 40\n",
    "ntest = 40\n",
    "intro = f\"You are an expert text classifier that assigns labels based on specific rules. You will be provided with exactly {ntrain} training examples that demonstrate the classification rule, followed by exactly {ntest} test examples that you need to classify using the same rule.\"\n",
    "question = \"Classify each of the following test examples as either True or False based on the pattern you observed in the training data:\"\n",
    "instructions = \"Examine the training examples carefully to determine the classification rule. Then, apply this rule to each test example. Respond with ONLY the labels (True or False) for each test example, one per line, without any additional text or explanation.\"\n",
    "outro = f\"Remember to output only True or False for each of the {ntest} test examples, maintaining the same order as presented. Do not include any other text in your response.\"\n",
    "\n",
    "# natural language articulation\n",
    "classification_prompt = build_classification_prompt(\n",
    "    \"datasets/ft_maxapples_AB_split_30.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "\n",
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "73323460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_accuracies': [np.float64(0.575), np.float64(0.6), np.float64(0.6), np.float64(0.575)], 'mean_accuracy': 0.5874999999999999, 'std_accuracy': 0.012500000000000011, 'overall_accuracy': 0.5875, 'all_outs': ['False\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse', 'False\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse', 'False\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse', 'False\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nTrue\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nTrue\\nTrue\\nFalse\\nTrue\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nTrue\\nFalse\\nFalse\\nFalse\\nFalse\\nTrue\\nFalse']}\n"
     ]
    }
   ],
   "source": [
    "gold_labels = load_expected_labels(\"datasets/ft_maxapples_AB_split_40.json\")\n",
    "# Build the model/temperature‑specific inference function\n",
    "inference_fn = make_inference_fn(model_name=openai_4op1, temperature=0.7)\n",
    "\n",
    "# Evaluate accuracy (gold_labels loaded elsewhere)\n",
    "results = evaluate_classification_accuracy(\n",
    "    prompt=classification_prompt,\n",
    "    inference_fn=inference_fn,\n",
    "    expected_labels=gold_labels,\n",
    "    label_set=[\"TRUE\", \"FALSE\"],\n",
    "    num_runs=4\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1af3e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Choice 1 (openai/gpt-4.1) —\n",
      "The answer is True if and only if the option selected contains at least 5 apples.\n",
      "\n",
      "— Choice 2 (openai/gpt-4.1) —\n",
      "The answer is True if and only if the selected option contains at least 5 apples.\n",
      "\n",
      "— Choice 3 (openai/gpt-4.1) —\n",
      "Select the option that contains at least 5 apples.\n",
      "\n",
      "— Choice 4 (openai/gpt-4.1) —\n",
      "The chosen option is labeled True if it contains at least 5 apples, regardless of type or variety.\n",
      "\n",
      "— Choice 5 (openai/gpt-4.1) —\n",
      "Choose the option that contains at least 5 apples and does not contain only apples (i.e., the option includes at least 5 apples plus at least one additional non-apple item).\n"
     ]
    }
   ],
   "source": [
    "# natural language articulation\n",
    "intro = \"You are an expert pattern recognizer tasked with identifying classification rules in data. You will be provided with labeled examples and asked to determine the underlying rule that distinguishes True from False cases.\"\n",
    "question = \"What is the exact rule that determines whether an example is labeled True or False?\"\n",
    "instructions = \"Analyze the pattern in the training examples carefully. Look for consistent features that separate True examples from False examples. Your rule should be precise enough to correctly classify new examples not in the training set. State the rule in a single, clear sentence. No explanations, no reasoning steps, no analysis of examples.\"\n",
    "articulation_prompt = build_articulation_prompt(\n",
    "    \"datasets/ft_maxapples_AB_split_40.json\",\n",
    "    intro=intro,\n",
    "    instructions=instructions,\n",
    "    question=question,\n",
    ")\n",
    "reply = await chat(openai_4op1, articulation_prompt, n=5, temperature=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
